"""Email query tool for MCP server"""

import logging
import csv
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

from infra.core import get_database_manager, get_logger
from infra.utils.datetime_parser import parse_date_range as util_parse_date_range, Timezone
from modules.mail_query import (
    MailQuerySeverFilters,
    MailQueryOrchestrator,
    MailQueryRequest,
    PaginationOptions
)
from modules.mail_process import AttachmentDownloader, FileConverterOrchestrator, EmailSaver
from modules.mail_process.client_filter import ClientFilter
from modules.mail_query_MCP.mcp_server.prompts import get_format_email_results_prompt

logger = get_logger(__name__)


class EmailQueryTool:
    """Tool for querying and retrieving emails"""

    def __init__(self, config):
        """
        Initialize email query tool

        Args:
            config: Configuration object
        """
        self.config = config
        self.email_saver = EmailSaver(output_dir=Path(self.config.emails_dir))
        self.attachment_downloader = AttachmentDownloader(
            output_dir=str(self.config.attachments_dir)
        )
        self.file_converter = FileConverterOrchestrator()
        # Define KST timezone (UTC+9) - for backward compatibility
        self.KST = timezone(timedelta(hours=9))

    def parse_datetime_kst_to_utc(self, date_str: str) -> datetime:
        """
        DEPRECATED: Use infra.utils.datetime_parser instead

        Kept for backward compatibility only.
        """
        from infra.utils.datetime_parser import parse_start_date
        # Return timezone-naive for backward compatibility
        return parse_start_date(date_str, input_tz=Timezone.KST, output_tz=Timezone.UTC).replace(tzinfo=None)

    def parse_date_range(self, arguments: Dict[str, Any]) -> tuple:
        """
        Parse date range from arguments using new datetime_parser utility

        Args:
            arguments: Tool arguments containing date parameters

        Returns:
            Tuple of (start_date, end_date, days_back)
        """
        start_date_str = arguments.get("start_date")
        end_date_str = arguments.get("end_date")
        days_back = arguments.get("days_back", self.config.default_days_back)

        # Use new datetime parser utility
        start_date, end_date, calculated_days = util_parse_date_range(
            start_date_str=start_date_str,
            end_date_str=end_date_str,
            days_back=days_back,
            input_tz=Timezone.KST,
            output_tz=Timezone.UTC
        )

        # Convert to timezone-naive for backward compatibility with MailQuerySeverFilters
        start_date = start_date.replace(tzinfo=None)
        end_date = end_date.replace(tzinfo=None)

        logger.info(f"ğŸ“… Date range parsed: {start_date_str} ~ {end_date_str} ({calculated_days} days)")
        logger.info(f"   Start (UTC): {start_date}")
        logger.info(f"   End (UTC):   {end_date}")

        return start_date, end_date, calculated_days

    async def validate_and_prepare_user(self, arguments: Dict[str, Any]) -> tuple[Optional[str], Optional[str]]:
        """
        Validate query parameters and prepare user_id with auto-authentication if needed

        Args:
            arguments: Tool arguments containing:
                - user_id (optional): íŠ¹ì • ê³„ì • ì§€ì •
                - use_recent_account (bool): Trueì´ë©´ ìµœê·¼ ì‚¬ìš© ê³„ì • ìë™ ì„ íƒ

        Returns:
            Tuple of (user_id, error_message). If error_message is not None, user_id should be ignored.
        """
        from datetime import datetime, timezone

        user_id = arguments.get("user_id")
        use_recent_account = arguments.get("use_recent_account", False)

        # Case 1: user_id ì œê³µ
        if user_id:
            logger.info(f"âœ… ì§€ì •ëœ user_id ì‚¬ìš©: {user_id}")

        # Case 2: use_recent_account=True
        elif use_recent_account:
            logger.info("use_recent_account=true - ìµœê·¼ ì‚¬ìš© ê³„ì • ìë™ ì„ íƒ")
            from ..handlers import get_default_user_id
            user_id = get_default_user_id()

            if not user_id:
                return None, """âŒ Error: use_recent_account=trueì´ì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ ê³„ì •ì´ ì—†ìŠµë‹ˆë‹¤.

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:
1. user_idë¥¼ ì œê³µí•˜ì—¬ íŠ¹ì • ê³„ì • ì¡°íšŒ
2. register_accountë¡œ ê³„ì •ì„ ë¨¼ì € ë“±ë¡"""

            logger.info(f"âœ… ìµœê·¼ ì‚¬ìš© ê³„ì • ì„ íƒ: {user_id}")
            # Update arguments with auto-selected user_id
            arguments["user_id"] = user_id

        # Case 3: ë‘˜ ë‹¤ ì—†ìŒ
        else:
            return None, """âŒ Error: user_id ë˜ëŠ” use_recent_account=trueê°€ í•„ìš”í•©ë‹ˆë‹¤.

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:
1. user_idë¥¼ ì œê³µí•˜ì—¬ íŠ¹ì • ê³„ì • ì¡°íšŒ
2. use_recent_account=trueë¡œ ì„¤ì •í•˜ì—¬ ìµœê·¼ ì‚¬ìš© ê³„ì • ì‚¬ìš©"""

        # Check token validity
        db = get_database_manager()
        account = db.fetch_one(
            "SELECT access_token, token_expiry FROM accounts WHERE user_id = ? AND is_active = 1",
            (user_id,)
        )

        if not account:
            return None, f"âŒ Error: ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}"

        # Convert sqlite3.Row to dict for .get() method
        account_dict = dict(account)
        access_token = account_dict.get('access_token')
        token_expiry = account_dict.get('token_expiry')

        # Check if authentication is required
        requires_auth = False
        if not access_token or not token_expiry:
            requires_auth = True
            logger.warning(f"âš ï¸  í† í°ì´ ì—†ìŒ: {user_id}")
        else:
            # Check token expiry
            try:
                if isinstance(token_expiry, str):
                    if '.' in token_expiry:
                        token_expiry = token_expiry.split('.')[0]
                    expiry_dt = datetime.fromisoformat(token_expiry.replace('Z', '+00:00'))
                else:
                    expiry_dt = token_expiry

                if expiry_dt.tzinfo is None:
                    expiry_dt = expiry_dt.replace(tzinfo=timezone.utc)

                now = datetime.now(timezone.utc)
                if expiry_dt <= now:
                    requires_auth = True
                    logger.warning(f"âš ï¸  í† í° ë§Œë£Œë¨: {user_id} (ë§Œë£Œ: {expiry_dt})")
            except Exception as e:
                requires_auth = True
                logger.error(f"âš ï¸  í† í° ë§Œë£Œ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {e}")

        # If authentication required, start authentication automatically
        if requires_auth:
            logger.info(f"ğŸ” ì¸ì¦ í•„ìš” - ìë™ìœ¼ë¡œ start_authentication ì‹œì‘: {user_id}")

            try:
                # Import here to avoid circular dependency
                from modules.enrollment.auth import get_auth_orchestrator, AuthStartRequest

                orchestrator = get_auth_orchestrator()
                request = AuthStartRequest(user_id=user_id)
                response = await orchestrator.auth_orchestrator_start_authentication(request)

                error_msg = f"""âš ï¸  ê³„ì • ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤: {user_id}

ğŸ” OAuth ì¸ì¦ì´ ìë™ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

ì„¸ì…˜ ID: {response.session_id}
ë§Œë£Œ ì‹œê°„: {response.expires_at}

ğŸŒ **ì¸ì¦ URL (í´ë¦­í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°):**

[Microsoft ë¡œê·¸ì¸ í˜ì´ì§€ ì—´ê¸°]({response.auth_url})

ë˜ëŠ” ì•„ë˜ URLì„ ì§ì ‘ ë³µì‚¬í•˜ì„¸ìš”:
```
{response.auth_url}
```

âœ… ë¸Œë¼ìš°ì €ì—ì„œ ë¡œê·¸ì¸ í›„ ê¶Œí•œ ìŠ¹ì¸ì„ ì™„ë£Œí•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì¦ì´ ì™„ë£Œë©ë‹ˆë‹¤.
   ì¸ì¦ ì™„ë£Œ í›„ ë‹¤ì‹œ `query_email`ì„ ì‹¤í–‰í•˜ì„¸ìš”."""

                return None, error_msg

            except Exception as e:
                logger.error(f"âŒ ìë™ ì¸ì¦ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
                return None, f"âŒ Error: ì¸ì¦ í•„ìš”í•˜ì§€ë§Œ ìë™ ì¸ì¦ ì‹œì‘ ì‹¤íŒ¨: {str(e)}\nìˆ˜ë™ìœ¼ë¡œ start_authenticationì„ ì‹¤í–‰í•˜ì„¸ìš”."

        # Validation successful - token is valid
        return user_id, None

    def validate_parameters(self, arguments: Dict[str, Any]) -> Optional[str]:
        """
        Validate query parameters (called after validate_and_prepare_user)

        Args:
            arguments: Tool arguments

        Returns:
            Error message if validation fails, None otherwise
        """
        # Check for conflicting parameters
        conversation_with = arguments.get("conversation_with", [])
        sender_address = arguments.get("sender_address")
        recipient_address = arguments.get("recipient_address")

        if conversation_with and sender_address:
            return "Error: conversation_with cannot be used with sender_address"
        if conversation_with and recipient_address:
            return "Error: conversation_with cannot be used with recipient_address"
        if sender_address and recipient_address:
            return "Error: sender_address and recipient_address cannot be used together"

        return None


    def filter_messages(self, messages: List, user_id: str, filters: Dict) -> List:
        """
        Filter messages: Keyword â†’ Conversation (blockingì€ mail_queryì—ì„œ ì²˜ë¦¬ë¨)

        Args:
            messages: List of email messages
            user_id: User ID
            filters: Filter parameters (conversation_with, recipient_address, keyword_filter)

        Returns:
            Filtered list of messages
        """
        conversation_with = filters.get("conversation_with", [])
        recipient_address = filters.get("recipient_address")
        keyword_filter = filters.get("keyword_filter")

        # 1ìˆœìœ„: í‚¤ì›Œë“œ í•„í„°
        if keyword_filter:
            messages = KeywordFilter.filter_by_keywords(messages, keyword_filter)

        # Apply conversation filter
        if conversation_with:
            messages = ConversationFilter.filter_conversation(messages, user_id, conversation_with)
            return messages

        # Apply recipient filter
        if recipient_address:
            # Filter for sent mails to specific recipient
            filtered_messages = []
            for mail in messages:
                sender_email = ""
                if mail.from_address and isinstance(mail.from_address, dict):
                    email_addr = mail.from_address.get("emailAddress", {})
                    sender_email = email_addr.get("address", "").lower()

                # Only include if this is a sent mail from the user
                if sender_email and f"{user_id}@" in sender_email:
                    # Check recipients
                    if hasattr(mail, "to_recipients") and mail.to_recipients:
                        for recipient in mail.to_recipients:
                            if isinstance(recipient, dict):
                                recip_addr = recipient.get("emailAddress", {})
                                if isinstance(recip_addr, dict):
                                    recip_email = recip_addr.get("address", "").lower()
                                    if recip_email == recipient_address.lower():
                                        filtered_messages.append(mail)
                                        break
            return filtered_messages

        return messages

    async def format_email_info(self, mail, index: int, user_id: str, save_emails: bool,
                          download_attachments: bool, graph_client=None) -> Dict[str, Any]:
        """
        Format email information for display and storage

        Args:
            mail: Email message object
            index: Email index
            user_id: User ID
            save_emails: Whether to save emails
            download_attachments: Whether to download attachments
            graph_client: Graph API client for attachment download

        Returns:
            Formatted email information dictionary
        """
        # Extract sender info
        sender = "Unknown"
        sender_email = None
        if mail.from_address and isinstance(mail.from_address, dict):
            email_addr = mail.from_address.get("emailAddress", {})
            sender_email = email_addr.get("address", "Unknown")
            sender = sender_email
            sender_name = email_addr.get("name", "")
            if sender_name:
                sender = f"{sender_name} <{sender_email}>"

        # Save email if requested
        mail_saved_path = None
        if save_emails:
            try:
                # Convert mail object to dictionary for EmailSaver
                from pathlib import Path
                email_dict = {
                    'id': mail.id,
                    'subject': mail.subject,
                    'received_date_time': mail.received_date_time,
                    'from': mail.from_address,
                    'body': mail.body,
                    'to_recipients': getattr(mail, 'to_recipients', []),
                    'cc_recipients': getattr(mail, 'cc_recipients', []),
                }
                # Create email directory based on user_id and date
                email_dir = Path(f"./data/emails/{user_id}/{mail.received_date_time.strftime('%Y%m%d')}")
                saved_info = await self.email_saver.save_email(email_dict, email_dir=email_dir)
                mail_saved_path = saved_info.get('text_path')
                logger.info(f"Email saved: {mail_saved_path}")
            except Exception as e:
                logger.error(f"Failed to save email: {str(e)}")

        # Convert received time to KST for display
        received_kst = mail.received_date_time.replace(tzinfo=timezone.utc).astimezone(self.KST)

        # Collect mail info
        mail_info = {
            "id": mail.id,
            "subject": mail.subject,
            "sender": sender,
            "sender_email": sender_email or "unknown@email.com",
            "received_date": received_kst.strftime("%Y-%m-%d %H:%M"),
            "received_date_time": mail.received_date_time,
            "has_attachments": mail.has_attachments,
            "is_read": mail.is_read,
            "importance": mail.importance,
            "attachments": [],
            "saved_path": mail_saved_path
        }

        # Add body content if available
        if mail.body:
            content_type = mail.body.get("contentType", "text")
            content = mail.body.get("content", "")

            if content_type.lower() == "html":
                # Simple HTML stripping
                import re
                text_content = re.sub("<[^<]+?>", "", content)
                text_content = text_content.replace("&nbsp;", " ")
                text_content = text_content.replace("&lt;", "<")
                text_content = text_content.replace("&gt;", ">")
                text_content = text_content.replace("&amp;", "&")
                # Don't truncate - include full body
                mail_info["body"] = text_content
            else:
                # Don't truncate - include full body
                mail_info["body"] = content
        elif mail.body_preview:
            mail_info["body_preview"] = mail.body_preview

        # Process attachments if requested
        if download_attachments and mail.has_attachments and hasattr(mail, "attachments"):
            if mail.attachments:
                for attachment in mail.attachments:
                    att_info = await self.process_attachment(
                        attachment, mail.id, user_id, graph_client
                    )
                    if att_info:
                        mail_info["attachments"].append(att_info)

        return mail_info

    async def process_attachment(self, attachment: Dict, mail_id: str, user_id: str,
                          graph_client) -> Optional[Dict]:
        """
        Process a single attachment

        Args:
            attachment: Attachment data
            mail_id: Email ID
            user_id: User ID
            graph_client: Graph API client

        Returns:
            Attachment information or None if processing failed
        """
        try:
            att_name = attachment.get("name", "unknown")
            att_size = attachment.get("size", 0)
            att_id = attachment.get("id")

            # Skip if too large
            if att_size > self.config.max_file_size_mb * 1024 * 1024:
                logger.warning(f"Attachment too large: {att_name} ({att_size} bytes)")
                return {
                    "name": att_name,
                    "size": att_size,
                    "status": "skipped_too_large"
                }

            # Download attachment
            if att_id and graph_client:
                saved_result = await self.attachment_downloader.download_and_save(
                    graph_client=graph_client,
                    user_id=user_id,
                    message_id=mail_id,
                    attachment=attachment
                )

                if saved_result and saved_result.get("file_path"):
                    saved_path = saved_result["file_path"]
                    result = {
                        "name": att_name,
                        "size": att_size,
                        "saved_path": str(saved_path),
                        "status": "downloaded"
                    }

                    # Convert to text if possible
                    try:
                        text_content = self.file_converter.convert_to_text(Path(saved_path))
                        if text_content and not text_content.startswith("Error:"):
                            # Calculate token count before truncation
                            original_token_count = len(text_content) // 4

                            # Limit text length to prevent excessive token usage
                            max_length = 5000
                            is_truncated = False
                            if len(text_content) > max_length:
                                text_content = text_content[:max_length] + f"\n\n... (truncated, total {len(text_content)} chars, ~{original_token_count} tokens)"
                                is_truncated = True

                            result["text_content"] = text_content
                            result["token_count"] = len(text_content) // 4
                            result["original_token_count"] = original_token_count
                            result["is_truncated"] = is_truncated
                            result["status"] = "converted"
                            logger.info(f"Successfully converted attachment to text: {att_name} ({len(text_content)} chars, ~{result['token_count']} tokens)")

                            # Delete attachment file after successful conversion if cleanup is enabled
                            if self.config.cleanup_after_query:
                                try:
                                    import os
                                    file_path = Path(saved_path)
                                    parent_dir = file_path.parent

                                    # Delete the file
                                    os.remove(saved_path)
                                    logger.info(f"Deleted attachment file after conversion: {saved_path}")
                                    result["file_deleted"] = True

                                    # Try to delete parent directory if empty
                                    try:
                                        if parent_dir.exists() and not any(parent_dir.iterdir()):
                                            parent_dir.rmdir()
                                            logger.info(f"Deleted empty directory: {parent_dir}")

                                            # Try to delete grandparent directory if empty (user_id folder)
                                            grandparent_dir = parent_dir.parent
                                            if grandparent_dir.exists() and not any(grandparent_dir.iterdir()):
                                                grandparent_dir.rmdir()
                                                logger.info(f"Deleted empty directory: {grandparent_dir}")
                                    except Exception as dir_error:
                                        # Ignore directory deletion errors (not critical)
                                        logger.debug(f"Could not delete empty directory: {str(dir_error)}")

                                except Exception as delete_error:
                                    logger.warning(f"Failed to delete attachment file: {saved_path} - {str(delete_error)}")
                                    result["file_deleted"] = False
                        else:
                            logger.warning(f"Failed to convert attachment: {att_name} - {text_content}")
                    except Exception as e:
                        logger.warning(f"Could not convert attachment to text: {att_name} - {str(e)}")

                    return result

            return {
                "name": att_name,
                "size": att_size,
                "status": "failed"
            }

        except Exception as e:
            logger.error(f"Error processing attachment: {str(e)}")
            return None

    async def query_email(self, arguments: Dict[str, Any]) -> str:
        """
        Handle mail query with attachments

        Args:
            arguments: Tool arguments

        Returns:
            Query result as formatted string
        """
        try:
            # Validate and prepare user (auto-select, auto-authenticate)
            user_id, error = await self.validate_and_prepare_user(arguments)
            if error:
                return error

            # Validate parameters
            error = self.validate_parameters(arguments)
            if error:
                return error

            # Extract parameters (user_id is already set by validate_and_prepare_user)
            # user_id = arguments.get("user_id")  # Already validated above
            max_mails = arguments.get("max_mails", self.config.default_max_mails)
            include_body = arguments.get("include_body", True)
            download_attachments = arguments.get("download_attachments", False)
            save_emails = arguments.get("save_emails", True)
            save_csv = arguments.get("save_csv", False)
            output_format = arguments.get("output_format", "text")

            # Parse date range
            try:
                start_date, end_date, days_back = self.parse_date_range(arguments)
            except ValueError as e:
                return f"Error: {str(e)}"

            # Create mail query
            orchestrator = MailQueryOrchestrator()

            # Setup filters - keyword_filter will be applied client-side, not server-side
            keyword_filter = None

            # Handle keyword_filter parameter (structured)
            keyword_filter_dict = arguments.get("keyword_filter")
            if keyword_filter_dict:
                from modules.mail_query import KeywordFilter
                keyword_filter = KeywordFilter(**keyword_filter_dict)

            # Handle legacy keyword parameter (simple string)
            keyword = arguments.get("keyword")
            if keyword and not keyword_filter:
                from modules.mail_query import KeywordFilter
                # Convert simple keyword to and_keywords for backward compatibility
                keyword_filter = KeywordFilter(and_keywords=[keyword])

            # Traditional filtering with date range
            filters = MailQuerySeverFilters(date_from=start_date, date_to=end_date)

            if arguments.get("sender_address"):
                filters.sender_address = arguments["sender_address"]

            if arguments.get("subject_contains"):
                filters.subject_contains = arguments["subject_contains"]

            # Setup fields
            select_fields = [
                "id", "subject", "from", "sender", "receivedDateTime",
                "bodyPreview", "hasAttachments", "importance", "isRead"
            ]
            if include_body:
                select_fields.append("body")
            if download_attachments:
                select_fields.append("attachments")

            # Adjust query for conversation filters or keyword
            conversation_with = arguments.get("conversation_with", [])
            recipient_address = arguments.get("recipient_address")

            # If using client-side filters (keyword_filter, conversation_with, recipient_address),
            # fetch more emails to filter from
            if keyword_filter or conversation_with or recipient_address:
                if "toRecipients" not in select_fields:
                    select_fields.append("toRecipients")
                # Fetch more emails when using client-side filtering
                query_max_mails = min(max_mails * 3, 500)  # Get more for filtering
            else:
                query_max_mails = max_mails

            # Create request (blocked_sendersë¥¼ mail_queryì— ì „ë‹¬)
            request = MailQueryRequest(
                user_id=user_id,
                filters=filters,
                pagination=PaginationOptions(top=query_max_mails, skip=0, max_pages=1),
                select_fields=select_fields,
                blocked_senders=self.config.blocked_senders,  # â­ mail_queryì—ì„œ blocking ì²˜ë¦¬
            )

            # Execute query
            async with orchestrator:
                response = await orchestrator.mail_query_user_emails(request)
                graph_client = orchestrator.graph_client if download_attachments else None

            # â­ Always apply blocking + optional filters (client-side filtering)
            response.messages = self.filter_messages(
                response.messages,
                user_id,
                {
                    "keyword_filter": keyword_filter,
                    "conversation_with": conversation_with,
                    "recipient_address": recipient_address
                }
            )
            # Limit to max_mails after filtering
            response.messages = response.messages[:max_mails]

            # Update last_used_at for the account
            try:
                from datetime import datetime, timezone
                db = get_database_manager()
                now_utc = datetime.now(timezone.utc).isoformat()
                db.execute_query(
                    "UPDATE accounts SET last_used_at = ? WHERE user_id = ?",
                    (now_utc, user_id)
                )
                logger.info(f"âœ… last_used_at ì—…ë°ì´íŠ¸ ì™„ë£Œ: {user_id}")
            except Exception as e:
                logger.warning(f"âš ï¸  last_used_at ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {str(e)}")

            # Format results
            result_text = await self.format_results(
                response.messages,
                user_id,
                start_date,
                end_date,
                days_back,
                arguments,
                save_emails,
                download_attachments,
                graph_client,
                save_csv
            )

            return result_text

        except Exception as e:
            logger.error(f"Error in query_email: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return f"Error querying emails: {str(e)}"

    async def format_results(self, messages: List, user_id: str, start_date, end_date,
                       days_back: int, filters: Dict, save_emails: bool,
                       download_attachments: bool, graph_client, save_csv: bool) -> str:
        """
        Format query results for display

        Args:
            messages: List of email messages
            user_id: User ID
            start_date: Query start date
            end_date: Query end date
            days_back: Number of days queried
            filters: Applied filters
            save_emails: Whether emails were saved
            download_attachments: Whether attachments were downloaded
            graph_client: Graph API client
            save_csv: Whether to save as CSV

        Returns:
            Formatted result string
        """
        result_text = f"ğŸ“§ ë©”ì¼ ì¡°íšŒ ê²°ê³¼ - {user_id}\n"
        result_text += f"{'='*60}\n"

        # Display date range info (convert UTC back to KST for display)
        if start_date and end_date:
            start_kst = start_date.replace(tzinfo=timezone.utc).astimezone(self.KST)
            end_kst = end_date.replace(tzinfo=timezone.utc).astimezone(self.KST)
            result_text += f"ì¡°íšŒ ê¸°ê°„: {start_kst.strftime('%Y-%m-%d %H:%M')} ~ "
            result_text += f"{end_kst.strftime('%Y-%m-%d %H:%M')} KST ({days_back}ì¼ê°„)\n"
        else:
            result_text += f"ì¡°íšŒ ê¸°ê°„: ìµœê·¼ {days_back}ì¼\n"

        # Display filters if applied
        if filters.get("conversation_with"):
            result_text += f"ëŒ€í™” í•„í„°: {', '.join(filters['conversation_with'])}\n"
        if filters.get("sender_address"):
            result_text += f"ë°œì‹ ì í•„í„°: {filters['sender_address']}\n"
        if filters.get("recipient_address"):
            result_text += f"ìˆ˜ì‹ ì í•„í„°: {filters['recipient_address']}\n"
        if filters.get("subject_contains"):
            result_text += f"ì œëª© í•„í„°: '{filters['subject_contains']}' í¬í•¨\n"

        # Process each mail first to get accurate count
        processed_mails = []
        mail_map = {}  # mail_infoì™€ ì›ë³¸ mail ê°ì²´ ë§¤í•‘
        for i, mail in enumerate(messages, 1):
            mail_info = await self.format_email_info(
                mail, i, user_id, save_emails, download_attachments, graph_client
            )

            if mail_info:  # Skip if None (blocked sender)
                processed_mails.append(mail_info)
                mail_map[mail_info['id']] = mail

        # Display result summary
        filtered_count = len(processed_mails)
        result_text += f"ì¡°íšŒëœ ë©”ì¼: {filtered_count}ê°œ"

        # Show what was included in the query
        query_details = []
        if filters.get("include_body"):
            query_details.append("ë³¸ë¬¸ í¬í•¨")
        else:
            query_details.append("ì œëª©ë§Œ")

        if download_attachments:
            query_details.append("ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ")

        if query_details:
            result_text += f" ({', '.join(query_details)})"

        result_text += "\n\n"

        # Display each mail
        for i, mail_info in enumerate(processed_mails, 1):
            mail = mail_map.get(mail_info['id'])

            # Add to result text
            result_text += f"\n[{i}] {mail_info['subject']}\n"
            result_text += f"   ë°œì‹ ì: {mail_info['sender']}\n"
            result_text += f"   ìˆ˜ì‹ ì¼: {mail_info['received_date']} KST\n"
            result_text += f"   ì½ìŒ: {'âœ“' if mail_info['is_read'] else 'âœ—'}\n"
            result_text += f"   ì²¨ë¶€: {'ğŸ“' if mail_info['has_attachments'] else '-'}\n"

            if save_emails and mail_info.get('saved_path'):
                result_text += f"   ğŸ’¾ ì €ì¥ë¨: {mail_info['saved_path']}\n"

            # Include body preview if available
            if filters.get("include_body"):
                if mail_info.get("body"):
                    # Show full body without any truncation
                    result_text += f"   ë‚´ìš©: {mail_info['body']}\n"
                elif mail_info.get("body_preview"):
                    result_text += f"   ë¯¸ë¦¬ë³´ê¸°: {mail_info['body_preview']}\n"

            # Show attachment info
            if mail_info.get("attachments"):
                result_text += f"   ì²¨ë¶€íŒŒì¼ ({len(mail_info['attachments'])}ê°œ):\n"
                for att in mail_info["attachments"]:
                    status = att.get("status", "unknown")
                    result_text += f"     - {att['name']} ({att['size']:,} bytes) [{status}]\n"

                    # Include token count if converted
                    if att.get("token_count"):
                        token_info = f"~{att['token_count']} tokens"
                        if att.get("is_truncated"):
                            token_info += f" (ì›ë³¸: ~{att['original_token_count']} tokens)"
                        result_text += f"       ğŸ”¢ í† í°: {token_info}\n"

                    # Include converted text content if available
                    if att.get("text_content"):
                        result_text += f"       ğŸ“„ ë‚´ìš©:\n{att['text_content']}\n"

        # Save to CSV if requested
        if save_csv and processed_mails:
            csv_path = self.save_emails_to_csv(processed_mails, user_id)
            result_text += f"\n\nğŸ“Š CSV íŒŒì¼ ì €ì¥ë¨: {csv_path}"

        result_text += f"\n\nâœ… ì´ {len(processed_mails)}ê°œì˜ ì´ë©”ì¼ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."

        # Add query options summary
        result_text += self._get_query_options_summary(filters, download_attachments)

        # Add formatting instructions from prompts.py
        result_text += f"\n\n{'='*80}\n"
        result_text += "ğŸ“‹ **ê²°ê³¼ í¬ë§·íŒ… ìš”ì²­**\n"
        result_text += f"{'='*80}\n\n"
        result_text += self._get_format_instructions(user_id, output_format)

        return result_text

    def _get_query_options_summary(self, filters: Dict, download_attachments: bool) -> str:
        """í˜„ì¬ ì¡°íšŒ ì˜µì…˜ ìƒíƒœì™€ ì¶”ê°€ ì˜µì…˜ ì•ˆë‚´"""
        summary = f"\n\n{'='*80}\n"
        summary += "ğŸ“Œ **ì¡°íšŒ ì˜µì…˜ ìƒíƒœ**\n"
        summary += f"{'='*80}\n"

        # Current options
        include_body = filters.get("include_body", False)
        keyword = filters.get("keyword")
        keyword_filter = filters.get("keyword_filter")

        summary += "\n**í˜„ì¬ í™œì„±í™”ëœ ì˜µì…˜:**\n"
        active_options = []

        if include_body:
            active_options.append("âœ… ë³¸ë¬¸ í¬í•¨ (`include_body: true`)")
        else:
            active_options.append("âŒ ì œëª©ë§Œ ì¡°íšŒ (ë³¸ë¬¸ ë¯¸í¬í•¨)")

        if download_attachments:
            active_options.append("âœ… ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ (`download_attachments: true`)")
        else:
            active_options.append("âŒ ì²¨ë¶€íŒŒì¼ ë¯¸ë‹¤ìš´ë¡œë“œ")

        if keyword:
            active_options.append(f"âœ… í‚¤ì›Œë“œ ê²€ìƒ‰: '{keyword}' (`keyword: \"{keyword}\"`)")
        elif keyword_filter:
            active_options.append(f"âœ… ê³ ê¸‰ í‚¤ì›Œë“œ í•„í„° ì ìš© (`keyword_filter`)")
        else:
            active_options.append("âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ ë¯¸ì‚¬ìš©")

        for option in active_options:
            summary += f"- {option}\n"

        # Suggestions for inactive options
        summary += "\n**ğŸ“¢ ì‚¬ìš© ê°€ëŠ¥í•œ ì¡°íšŒ ë°©ë²•:**\n"
        suggestions = []

        suggestions.append("- **ë©”ì¼ ëª©ë¡ ì¡°íšŒ**: \"ìµœê·¼ 3ê°œì›” ê°„ kimghw ê³„ì •ì—ì„œ ì†¡ìˆ˜ì‹ í•œ ë©”ì¼ ì¡°íšŒí•´ì¤˜\"")
        suggestions.append("- **ë©”ì¼ ë³¸ë¬¸ ì¡°íšŒ**: \"ìµœê·¼ í•œë‹¬ ê°„ kimghw ê³„ì •ì—ì„œ ì†¡ìˆ˜ì‹ í•œ ë©”ì¼ì„ ë³¸ë¬¸ í¬í•¨í•˜ì—¬ ì œê³µí•´ì¤˜\"")
        suggestions.append("- **ì²¨ë¶€íŒŒì¼ í¬í•¨ ì¡°íšŒ**: \"ìµœê·¼ í•œë‹¬ ê°„ kimghw ê³„ì •ì— ì†¡ìˆ˜ì‹ í•œ ë©”ì¼ì„ ë³¸ë¬¸ê³¼ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ê¹Œì§€ ì¡°íšŒí•´ì¤˜\"")
        suggestions.append("- **í‚¤ì›Œë“œ ê²€ìƒ‰**: \"ìµœê·¼ 3ê°œì›” ê°„ 'PL25032' í‚¤ì›Œë“œì— ëŒ€í•´ kimghw ê³„ì •ì— ì†¡ìˆ˜ì‹ í•œ ë©”ì¼ì„ ë³¸ë¬¸, ì²¨ë¶€íŒŒì¼ê¹Œì§€ í¬í•¨í•´ì„œ ì¡°íšŒí•´ì¤˜\"")

        for suggestion in suggestions:
            summary += f"{suggestion}\n"

        summary += "\nğŸ’¡ ìœ„ í‘œí˜„ìœ¼ë¡œ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

        return summary

    def _get_format_instructions(self, user_id: str, output_format: str = "text") -> str:
        """Get email formatting instructions from prompts.py"""
        # Map output_format to format_style
        format_style = "table" if output_format == "text" else "json"
        return get_format_email_results_prompt(
            format_style=format_style,
            include_attachments=True,
            user_id=user_id
        )

    def save_emails_to_csv(self, emails: List[Dict[str, Any]], user_id: str) -> Path:
        """
        Save email data to CSV file

        Args:
            emails: List of email dictionaries
            user_id: User ID

        Returns:
            Path to saved CSV file
        """
        # Create output directory
        csv_dir = Path(self.config.save_directory) / user_id / "exports"
        csv_dir.mkdir(parents=True, exist_ok=True)

        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = csv_dir / f"email_metadata_{timestamp}.csv"

        # Write CSV
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            if emails:
                # Define field names
                fieldnames = [
                    'subject', 'sender', 'sender_email', 'received_date',
                    'has_attachments', 'is_read', 'importance', 'body_preview'
                ]

                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()

                for email in emails:
                    row = {
                        'subject': email.get('subject', ''),
                        'sender': email.get('sender', ''),
                        'sender_email': email.get('sender_email', ''),
                        'received_date': email.get('received_date', ''),
                        'has_attachments': email.get('has_attachments', False),
                        'is_read': email.get('is_read', False),
                        'importance': email.get('importance', 'normal'),
                        'body_preview': email.get('body', '')[:200] if email.get('body') else email.get('body_preview', '')[:200]
                    }
                    writer.writerow(row)

        logger.info(f"CSV file saved: {csv_file}")
        return csv_file
