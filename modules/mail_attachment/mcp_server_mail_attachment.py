"""HTTP Streaming-based MCP Server for Mail Attachments

This server uses HTTP streaming (chunked transfer encoding) for communication.
Provides email and attachment querying capabilities through MCP protocol.
"""

import asyncio
import csv
import json
import logging
import os
import secrets
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, AsyncIterator, Dict, List, Optional

import uvicorn
from mcp.server import NotificationOptions, Server
from mcp.server.models import InitializationOptions
from mcp.types import Prompt, PromptArgument, PromptMessage, TextContent, Tool
from pydantic import BaseModel, Field
from starlette.applications import Starlette
from starlette.requests import Request
from starlette.responses import JSONResponse, Response, StreamingResponse
from starlette.routing import Route

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from infra.core.auth_logger import get_auth_logger
from infra.core.database import get_database_manager
from infra.core.logger import get_logger
from modules.mail_attachment import AttachmentDownloader, EmailSaver, FileConverter
from modules.mail_query import (
    MailQueryFilters,
    MailQueryOrchestrator,
    MailQueryRequest,
    PaginationOptions,
)

logger = get_logger(__name__)
auth_logger = get_auth_logger()


class HTTPStreamingMailAttachmentServer:
    """HTTP Streaming-based MCP Server for Mail Attachments"""

    def __init__(self, host: str = "0.0.0.0", port: int = 8002):
        self.host = host
        self.port = port

        # MCP Server
        self.mcp_server = Server("mail-attachment-server")

        # Database
        self.db = get_database_manager()

        # Initialize database connection and check authentication
        self._initialize_and_check_auth()

        # Attachment handling components
        self.attachment_downloader = AttachmentDownloader("./mcp_attachments")
        self.file_converter = FileConverter()
        self.email_saver = EmailSaver("./mcp_attachments")

        # Active sessions
        self.sessions: Dict[str, Dict[str, Any]] = {}

        # Store handlers for direct access
        self._handlers = {}

        # Register handlers
        self._register_handlers()

        # Create Starlette app
        self.app = self._create_app()

        logger.info(
            f"ğŸš€ HTTP Streaming Mail Attachment Server initialized on port {port}"
        )

    def _initialize_and_check_auth(self):
        """Initialize database connection and check authentication status"""
        logger.info("ğŸ” Initializing database and checking authentication...")

        try:
            # Force database connection initialization
            query = "SELECT COUNT(*) FROM accounts WHERE is_active = 1"
            result = self.db.fetch_one(query)
            active_accounts = result[0] if result else 0

            logger.info(f"âœ… Database connection successful")
            logger.info(f"ğŸ“Š Active accounts found: {active_accounts}")

            # Check authentication status for all active accounts
            if active_accounts > 0:
                auth_query = """
                SELECT user_id, 
                       CASE 
                           WHEN access_token IS NOT NULL AND token_expiry > datetime('now') THEN 'VALID'
                           WHEN refresh_token IS NOT NULL THEN 'REFRESH_NEEDED'
                           ELSE 'EXPIRED'
                       END as auth_status
                FROM accounts 
                WHERE is_active = 1
                ORDER BY user_id
                """
                auth_results = self.db.fetch_all(auth_query)

                logger.info("ğŸ” Authentication status:")

                # Count by status
                valid_count = sum(1 for row in auth_results if row[1] == "VALID")
                refresh_count = sum(
                    1 for row in auth_results if row[1] == "REFRESH_NEEDED"
                )
                expired_count = sum(1 for row in auth_results if row[1] == "EXPIRED")

                for row in auth_results:
                    user_id, status = row
                    status_emoji = (
                        "âœ…"
                        if status == "VALID"
                        else "âš ï¸" if status == "REFRESH_NEEDED" else "âŒ"
                    )
                    logger.info(f"   {status_emoji} {user_id}: {status}")
                    auth_logger.log_authentication(
                        user_id, status, "server startup check"
                    )

                # Log batch check summary
                auth_logger.log_batch_auth_check(
                    active_accounts, valid_count, refresh_count, expired_count
                )
            else:
                logger.warning("âš ï¸ No active accounts found in database")

        except Exception as e:
            logger.error(f"âŒ Failed to initialize database or check auth: {str(e)}")
            raise

    def _register_handlers(self):
        """Register MCP protocol handlers"""

        @self.mcp_server.list_tools()
        async def handle_list_tools() -> List[Tool]:
            """List available tools"""
            logger.info("ğŸ”§ [MCP Handler] list_tools() called")

            return [
                Tool(
                    name="query_email",
                    title="ğŸ“§ Query Email",
                    description="Query emails and download/convert attachments to text. Date priority: start_date/end_date > days_back",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "user_id": {
                                "type": "string",
                                "description": "User ID to query - email prefix without @domain (e.g., 'kimghw' for kimghw@krs.co.kr)",
                            },
                            "days_back": {
                                "type": "integer",
                                "description": "Number of days to look back",
                                "default": 30,
                            },
                            "max_mails": {
                                "type": "integer",
                                "description": "Maximum number of mails to retrieve",
                                "default": 300,
                            },
                            "include_body": {
                                "type": "boolean",
                                "description": "Include full email body content in the response. When true, returns complete HTML/text content of each email. When false, only returns email preview (first ~255 chars). Useful for detailed content analysis",
                                "default": True,
                            },
                            "download_attachments": {
                                "type": "boolean",
                                "description": "Download email attachments and convert supported formats (PDF, DOCX, XLSX, etc.) to text. When true, creates local copies and includes text content in response. When false, only shows attachment metadata (name, size)",
                                "default": False,
                            },
                            "has_attachments_filter": {
                                "type": "boolean",
                                "description": "Filter to retrieve only emails that contain attachments. When true, excludes all emails without attachments. When false or not specified, returns all emails regardless of attachment status",
                            },
                            "save_emails": {
                                "type": "boolean",
                                "description": "Save each email as individual text file to disk (mcp_attachments/{user_id}/). Files include headers, body, and attachment list. Useful for archiving or offline access. File names contain subject, date, and sender",
                                "default": True,
                            },
                            "save_csv": {
                                "type": "boolean",
                                "description": "Export all retrieved emails' metadata to a single CSV file. Includes: subject, sender, date, read status, importance, attachment count/names, body preview (100 chars). Excel-compatible format with UTF-8 BOM encoding",
                                "default": False,
                            },
                            "start_date": {
                                "type": "string",
                                "description": "Start date in YYYY-MM-DD format. When user says 'this week', calculate 7 days ago from today. When 'last month', calculate 30 days ago. When 'last 3 months', calculate 90 days ago.",
                            },
                            "end_date": {
                                "type": "string",
                                "description": "End date in YYYY-MM-DD format. When user mentions a time period without specific end date, use today's date. For 'this week' or 'last month', end_date should be today.",
                            },
                            "sender_address": {
                                "type": "string",
                                "description": "ğŸ“¥ ë°›ì€ ë©”ì¼ í•„í„°: íŠ¹ì • ë°œì‹ ìê°€ ë‚˜ì—ê²Œ ë³´ë‚¸ ë©”ì¼ë§Œ ì¡°íšŒ. ì˜ˆ: 'kim@company.com' â†’ kimì´ ë‚˜ì—ê²Œ ë³´ë‚¸ ë©”ì¼ë§Œ. (ë‚´ê°€ kimì—ê²Œ ë³´ë‚¸ ë©”ì¼ì€ í¬í•¨ ì•ˆ ë¨)",
                            },
                            "subject_contains": {
                                "type": "string",
                                "description": "Filter emails by subject text. Only emails containing this text in the subject will be retrieved. Case-insensitive partial matching (e.g., 'meeting' matches 'Weekly Meeting Report').",
                            },
                            "recipient_address": {
                                "type": "string",
                                "description": "ğŸ“¨ ë³´ë‚¸ ë©”ì¼ í•„í„°: ë‚´ê°€ íŠ¹ì • ìˆ˜ì‹ ìì—ê²Œ ë³´ë‚¸ ë©”ì¼ë§Œ ì¡°íšŒ. ì˜ˆ: 'kim@company.com' â†’ ë‚´ê°€ kimì—ê²Œ ë³´ë‚¸ ë©”ì¼ë§Œ. (kimì´ ë‚˜ì—ê²Œ ë³´ë‚¸ ë©”ì¼ì€ í¬í•¨ ì•ˆ ë¨)",
                            },
                            "conversation_with": {
                                "type": "array",
                                "items": {
                                    "type": "string"
                                },
                                "description": "ğŸ’¬ ëŒ€í™” ì „ì²´ ì¡°íšŒ: íŠ¹ì • ì‚¬ëŒê³¼ ì£¼ê³ ë°›ì€ ëª¨ë“  ë©”ì¼. ì˜ˆ: ['kim@company.com'] â†’ â‘ kimì´ ë‚˜ì—ê²Œ ë³´ë‚¸ ë©”ì¼ + â‘¡ë‚´ê°€ kimì—ê²Œ ë³´ë‚¸ ë©”ì¼ ëª¨ë‘ í¬í•¨. ì™„ì „í•œ ëŒ€í™” ë‚´ì—­ì„ ë³´ë ¤ë©´ ì´ê²ƒì„ ì‚¬ìš©í•˜ì„¸ìš”.",
                            },
                        },
                        "required": [
                            "user_id",
                            "start_date",
                            "end_date",
                            "max_mails",
                            "include_body",
                            "download_attachments",
                            "save_emails",
                            "save_csv",
                        ],
                    },
                ),
                Tool(
                    name="list_active_accounts",
                    title="ğŸ‘¥ List Active Email Accounts",
                    description="List all active email accounts",
                    inputSchema={"type": "object", "properties": {}},
                ),
                Tool(
                    name="convert_file_to_text",
                    title="ğŸ“„ Convert File to Text",
                    description="Convert a file (PDF, Word, Excel, etc.) to text",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "file_path": {
                                "type": "string",
                                "description": "Path to the file to convert",
                            }
                        },
                        "required": ["file_path"],
                    },
                ),
            ]

        # Store handler for direct access
        self._handlers["list_tools"] = handle_list_tools

        @self.mcp_server.call_tool()
        async def handle_call_tool(
            name: str, arguments: Dict[str, Any]
        ) -> List[TextContent]:
            """Handle tool calls"""
            logger.info(f"ğŸ› ï¸ [MCP Handler] call_tool() called with tool: {name}")
            logger.info(
                f"ğŸ“ [MCP Handler] Raw arguments: {json.dumps(arguments, indent=2, ensure_ascii=False)}"
            )

            # Preprocess arguments
            arguments = self._preprocess_arguments(arguments)
            logger.info(
                f"ğŸ”„ [MCP Handler] Preprocessed arguments: {json.dumps(arguments, indent=2, ensure_ascii=False)}"
            )

            try:
                if name == "query_email":
                    result = await self._handle_mail_query(arguments)
                    return [TextContent(type="text", text=result)]

                elif name == "list_active_accounts":
                    result = await self._handle_list_accounts()
                    return [TextContent(type="text", text=result)]

                elif name == "convert_file_to_text":
                    result = await self._handle_file_conversion(arguments)
                    return [TextContent(type="text", text=result)]

                else:
                    raise ValueError(f"Unknown tool: {name}")

            except Exception as e:
                logger.error(f"âŒ Error in tool {name}: {str(e)}", exc_info=True)
                return [TextContent(type="text", text=f"Error: {str(e)}")]

        # Store handler for direct access
        self._handlers["call_tool"] = handle_call_tool

        @self.mcp_server.list_prompts()
        async def handle_list_prompts() -> List[Prompt]:
            """List available prompts"""
            logger.info("ğŸ“‹ [MCP Handler] list_prompts() called")

            return [
                Prompt(
                    name="mail_attachment_query",
                    description="Query emails with attachment handling",
                    arguments=[
                        PromptArgument(
                            name="user_query",
                            description="Natural language query about emails",
                            required=True,
                        )
                    ],
                ),
                Prompt(
                    name="format_email_results",
                    description="Format email query results for user presentation",
                    arguments=[
                        PromptArgument(
                            name="format_style",
                            description="Formatting style (table, summary, detailed, bullet_points)",
                            required=True,
                        ),
                        PromptArgument(
                            name="include_attachments",
                            description="Whether to include attachment content in the summary",
                            required=False,
                        ),
                    ],
                ),
                Prompt(
                    name="attachment_summary_format",
                    description="Format attachment contents for clear user presentation",
                    arguments=[
                        PromptArgument(
                            name="summary_length",
                            description="Length of summary (brief, standard, detailed)",
                            required=True,
                        ),
                        PromptArgument(
                            name="highlight_sections",
                            description="Sections to highlight (dates, names, numbers, keywords)",
                            required=False,
                        ),
                    ],
                ),
            ]

        # Store handler for direct access
        self._handlers["list_prompts"] = handle_list_prompts

        @self.mcp_server.get_prompt()
        async def handle_get_prompt(
            name: str, arguments: Dict[str, Any]
        ) -> PromptMessage:
            """Get specific prompt"""
            logger.info(f"ğŸ“ [MCP Handler] get_prompt() called with prompt: {name}")

            if name == "mail_attachment_query":
                user_query = arguments.get("user_query", "")
                prompt_content = f"""
ë©”ì¼ ì²¨ë¶€íŒŒì¼ ì¡°íšŒ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆì˜: {user_query}

ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:
1. íŠ¹ì • ì‚¬ìš©ìì˜ ë©”ì¼ ì¡°íšŒ
2. ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë³€í™˜
3. ë‚ ì§œ ë²”ìœ„ ë° í•„í„° ì ìš©

ì¡°íšŒí•  ì‚¬ìš©ì IDì™€ ì¡°ê±´ì„ ì§€ì •í•´ì£¼ì„¸ìš”.
"""

            elif name == "format_email_results":
                format_style = arguments.get("format_style", "summary")
                include_attachments = arguments.get("include_attachments", True)
                user_id = arguments.get("user_id", "")

                prompt_content = f"""
ğŸ“§ ì´ë©”ì¼ ì¡°íšŒ ê²°ê³¼ í¬ë§·íŒ… ì§€ì¹¨

í¬ë§· ìŠ¤íƒ€ì¼: {format_style}
ì²¨ë¶€íŒŒì¼ í¬í•¨: {include_attachments}
ì¡°íšŒ ì‚¬ìš©ì: {user_id}

ë‹¤ìŒ ìˆœì„œì™€ í˜•ì‹ìœ¼ë¡œ í…Œì´ë¸”ì„ ì‘ì„±í•˜ì„¸ìš”:
** ëª¨ë“  ë©”ì¼ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ì„œ ì‘ì„±í•´ ì£¼ì„¸ìš” **

**ğŸ“Š í‘œ êµ¬ì„± (í•„ìˆ˜ ì—´)**:
| ìœ í˜• | ë‚ ì§œ | ë°œì‹ ì/ìˆ˜ì‹ ì | ì œëª© | ì£¼ìš”ë‚´ìš© | ì‘ë‹µí•„ìš”ì„± | ì‘ë‹µê¸°í•œ | ì²¨ë¶€ |

**ê° ì—´ ì‘ì„± ì§€ì¹¨**:
1. **ìœ í˜•**: 
   - ğŸ“¥ ë°›ì€ë©”ì¼: ë°œì‹ ì ì´ë©”ì¼ì´ ì¡°íšŒ ì‚¬ìš©ì({user_id})ì™€ ë‹¤ë¥¸ ê²½ìš°
   - ğŸ“¨ ë³´ë‚¸ë©”ì¼: ë°œì‹ ì ì´ë©”ì¼ì´ ì¡°íšŒ ì‚¬ìš©ì({user_id})ì™€ ê°™ì€ ê²½ìš°
2. **ë‚ ì§œ**: YYYY-MM-DD HH:MM í˜•ì‹
3. **ë°œì‹ ì/ìˆ˜ì‹ ì**: 
   - ë°›ì€ë©”ì¼: ë°œì‹ ì ì´ë¦„ (ì´ë©”ì¼)
   - ë³´ë‚¸ë©”ì¼: â†’ ìˆ˜ì‹ ì ì´ë¦„ (ì´ë©”ì¼)
4. **ì œëª©**: ì „ì²´ ì œëª© (ë„ˆë¬´ ê¸¸ë©´ ... ì‚¬ìš©)
5. **ì£¼ìš”ë‚´ìš©**: í•µì‹¬ ë‚´ìš© 1-2ì¤„ ìš”ì•½
6. **ì‘ë‹µí•„ìš”ì„±**: 
   - ë°›ì€ë©”ì¼: ğŸ”´ ì¤‘ìš” (ì‘ë‹µ í•„ìš”) / ğŸŸ¢ ì¼ë°˜ (ì°¸ê³ ìš©)
   - ë³´ë‚¸ë©”ì¼: âœ… ë°œì†¡ì™„ë£Œ / â³ ì‘ë‹µëŒ€ê¸°
7. **ì‘ë‹µê¸°í•œ**: êµ¬ì²´ì  ë‚ ì§œ ë˜ëŠ” "ì¦‰ì‹œ", "3ì¼ ë‚´", "ì—†ìŒ" ë“±
8. **ì²¨ë¶€**: íŒŒì¼ëª… (íŒŒì¼í˜•ì‹) ë˜ëŠ” "ì—†ìŒ"

**ì‘ë‹µ í•„ìš”ì„± íŒë‹¨ ê¸°ì¤€**:
- ì§ˆë¬¸ì´ í¬í•¨ëœ ê²½ìš°
- "íšŒì‹  ìš”ì²­", "ë‹µë³€ ë¶€íƒ" ë“±ì˜ í‘œí˜„
- ë§ˆê°ì¼ì´ ëª…ì‹œëœ ê²½ìš°
- ìŠ¹ì¸/ê²€í†  ìš”ì²­ì´ ìˆëŠ” ê²½ìš°

**ì˜ˆì‹œ**:
| ğŸ“¥ | 2024-01-15 09:30 | ê¹€ì² ìˆ˜ (kim@company.com) | í”„ë¡œì íŠ¸ ì§„í–‰ í˜„í™© ë³´ê³  | Q1 ëª©í‘œ ë‹¬ì„±ë¥  85%, ì¶”ê°€ ì˜ˆì‚° ìŠ¹ì¸ ìš”ì²­ | ğŸ”´ ê¸´ê¸‰ | 1/17ê¹Œì§€ | ë³´ê³ ì„œ.pdf |
| ğŸ“¨ | 2024-01-15 11:20 | â†’ ì´ì˜í¬ (lee@company.com) | Re: í”„ë¡œì íŠ¸ ì§„í–‰ í˜„í™© ë³´ê³  | ì˜ˆì‚° ìŠ¹ì¸ ì™„ë£Œ, ì§„í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤ | âœ… ë°œì†¡ì™„ë£Œ | - | - |

ì´ë©”ì¼ ë‚´ìš©ê³¼ ì²¨ë¶€íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì‘ë‹µ í•„ìš”ì„±ê³¼ ê¸°í•œì„ ì •í™•íˆ íŒë‹¨í•˜ì„¸ìš”.
"""

            elif name == "attachment_summary_format":
                summary_length = arguments.get("summary_length", "standard")
                highlight_sections = arguments.get("highlight_sections", "")

                prompt_content = f"""
ğŸ“ ì²¨ë¶€íŒŒì¼ ë‚´ìš© ìš”ì•½ ì§€ì¹¨

ìš”ì•½ ê¸¸ì´: {summary_length}
ê°•ì¡° ì„¹ì…˜: {highlight_sections}

ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì„ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”:

{'**ê°„ëµ ìš”ì•½** (3-5ì¤„)' if summary_length == 'brief' else ''}
{'- í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ' if summary_length == 'brief' else ''}
{'- ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ ìœ„ì£¼' if summary_length == 'brief' else ''}

{'**í‘œì¤€ ìš”ì•½** (10-15ì¤„)' if summary_length == 'standard' else ''}
{'- ì£¼ìš” ì„¹ì…˜ë³„ë¡œ ì •ë¦¬' if summary_length == 'standard' else ''}
{'- ì¤‘ìš” ë°ì´í„° í¬í•¨' if summary_length == 'standard' else ''}

{'**ìƒì„¸ ìš”ì•½** (ì „ì²´ êµ¬ì¡° í¬í•¨)' if summary_length == 'detailed' else ''}
{'- ëª¨ë“  ì„¹ì…˜ í¬í•¨' if summary_length == 'detailed' else ''}
{'- ì„¸ë¶€ ë‚´ìš©ê¹Œì§€ ì •ë¦¬' if summary_length == 'detailed' else ''}

{f'ê°•ì¡°í•  ë‚´ìš©: {highlight_sections}' if highlight_sections else ''}

í¬ë§· ê·œì¹™:
- ğŸ“… ë‚ ì§œëŠ” êµµê²Œ í‘œì‹œ
- ğŸ‘¤ ì¸ë¬¼ëª…ì€ ë°‘ì¤„
- ğŸ’° ê¸ˆì•¡/ìˆ«ìëŠ” í•˜ì´ë¼ì´íŠ¸
- ğŸ”‘ ì¤‘ìš” í‚¤ì›Œë“œëŠ” ë°±í‹±(`)ìœ¼ë¡œ ê°ì‹¸ê¸°

ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”.
"""

            else:
                raise ValueError(f"Unknown prompt: {name}")

            return PromptMessage(
                role="assistant", content=TextContent(type="text", text=prompt_content)
            )

        # Store handler for direct access
        self._handlers["get_prompt"] = handle_get_prompt

    def _preprocess_arguments(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Preprocess arguments from Claude Desktop"""
        import json

        # Clean backslashes from all string values
        def clean_backslashes(obj):
            if isinstance(obj, str):
                return obj.replace("\\", "")
            elif isinstance(obj, dict):
                return {k: clean_backslashes(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [clean_backslashes(item) for item in obj]
            return obj

        arguments = clean_backslashes(arguments)

        # Special handling for integer fields
        int_fields = ["days_back", "max_mails", "limit"]
        for field in int_fields:
            if field in arguments and isinstance(arguments[field], str):
                cleaned_value = arguments[field].strip().strip("'").strip('"')
                try:
                    arguments[field] = int(cleaned_value)
                except ValueError:
                    pass

        # Handle string-wrapped JSON
        if "extracted_period" in arguments and isinstance(
            arguments["extracted_period"], str
        ):
            try:
                arguments["extracted_period"] = json.loads(
                    arguments["extracted_period"]
                )
            except:
                pass

        if "extracted_keywords" in arguments and isinstance(
            arguments["extracted_keywords"], str
        ):
            try:
                arguments["extracted_keywords"] = json.loads(
                    arguments["extracted_keywords"]
                )
            except:
                pass

        # Handle string "null" to actual null
        null_fields = ["extracted_organization", "category", "query_scope", "intent"]
        for key in null_fields:
            if key in arguments and arguments[key] == "null":
                arguments[key] = None

        # Handle boolean fields
        bool_fields = [
            "include_body",
            "download_attachments",
            "has_attachments_filter",
            "execute",
            "use_defaults",
        ]
        for field in bool_fields:
            if field in arguments:
                if isinstance(arguments[field], str):
                    arguments[field] = arguments[field].lower() == "true"

        return arguments

    async def _handle_mail_query(self, arguments: Dict[str, Any]) -> str:
        """Handle mail query with attachments"""
        try:
            # Extract parameters
            user_id = arguments.get("user_id")
            if not user_id:
                return "Error: user_id is required"

            days_back = arguments.get("days_back", 30)
            max_mails = arguments.get("max_mails", 300)  # inputSchema defaultì™€ ì¼ì¹˜
            include_body = arguments.get("include_body", True)  # inputSchema defaultì™€ ì¼ì¹˜
            download_attachments = arguments.get("download_attachments", False)  # inputSchema defaultì™€ ì¼ì¹˜
            has_attachments_filter = arguments.get("has_attachments_filter")
            save_emails = arguments.get("save_emails", True)  # inputSchema defaultì™€ ì¼ì¹˜
            save_csv = arguments.get("save_csv", False)  # inputSchema defaultì™€ ì¼ì¹˜
            start_date_str = arguments.get("start_date")
            end_date_str = arguments.get("end_date")
            sender_address = arguments.get("sender_address")
            recipient_address = arguments.get("recipient_address")
            subject_contains = arguments.get("subject_contains")
            conversation_with = arguments.get("conversation_with", [])

            # Create mail query
            orchestrator = MailQueryOrchestrator()

            # Parse dates if provided - Priority: date range > days_back
            start_date = None
            end_date = None

            # Both dates specified
            if start_date_str and end_date_str:
                try:
                    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
                    end_date = datetime.strptime(end_date_str, "%Y-%m-%d")

                    if start_date > end_date:
                        return "Error: start_date is later than end_date"

                    # days_back is ignored when both dates are specified
                    days_back = (end_date - start_date).days + 1

                except ValueError as e:
                    return f"Error: Invalid date format. Expected YYYY-MM-DD. {str(e)}"

            # Only start date specified
            elif start_date_str:
                try:
                    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
                    end_date = datetime.now()
                    days_back = (end_date - start_date).days + 1
                except ValueError:
                    return f"Error: Invalid start_date format. Expected YYYY-MM-DD, got {start_date_str}"

            # Only end date specified
            elif end_date_str:
                try:
                    end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
                    start_date = end_date - timedelta(days=days_back - 1)
                except ValueError:
                    return f"Error: Invalid end_date format. Expected YYYY-MM-DD, got {end_date_str}"

            # No dates specified, use days_back from now
            else:
                end_date = datetime.now()
                start_date = end_date - timedelta(days=days_back - 1)

            # Check for conflicting parameters
            if conversation_with and sender_address:
                return "Error: conversation_with cannot be used with sender_address"
            if conversation_with and recipient_address:
                return "Error: conversation_with cannot be used with recipient_address"
            if sender_address and recipient_address:
                return "Error: sender_address and recipient_address cannot be used together"
            
            # Setup filters with the calculated date range
            filters = MailQueryFilters(date_from=start_date, date_to=end_date)

            if has_attachments_filter is not None:
                filters.has_attachments = has_attachments_filter
            
            if sender_address:
                filters.sender_address = sender_address
                
            if subject_contains:
                filters.subject_contains = subject_contains

            # Setup fields
            select_fields = [
                "id",
                "subject",
                "from",
                "sender",
                "receivedDateTime",
                "bodyPreview",
                "hasAttachments",
                "importance",
                "isRead",
            ]
            if include_body:
                select_fields.append("body")
            if download_attachments or has_attachments_filter:
                select_fields.append("attachments")

            # Adjust query for conversation_with or recipient_address
            if conversation_with or recipient_address:
                # For conversation_with/recipient_address, we need to get more emails and filter client-side
                # Also need toRecipients field
                if "toRecipients" not in select_fields:
                    select_fields.append("toRecipients")
                
                # Get more emails to ensure we find conversations
                query_max_mails = min(max_mails * 3, 500)  # Get 3x more, max 500
            else:
                query_max_mails = max_mails
            
            # Create request
            request = MailQueryRequest(
                user_id=user_id,
                filters=filters,
                pagination=PaginationOptions(top=query_max_mails, skip=0, max_pages=1),
                select_fields=select_fields,
            )

            # Execute query
            async with orchestrator:
                response = await orchestrator.mail_query_user_emails(request)
                graph_client = (
                    orchestrator.graph_client if download_attachments else None
                )

            # Format results
            result_text = f"ğŸ“§ ë©”ì¼ ì¡°íšŒ ê²°ê³¼ - {user_id}\n"
            result_text += f"{'='*60}\n"
            # Display date range info
            if start_date and end_date:
                result_text += f"ì¡°íšŒ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ({days_back}ì¼ê°„)\n"
            else:
                result_text += f"ì¡°íšŒ ê¸°ê°„: ìµœê·¼ {days_back}ì¼\n"
            
            # Display filters if applied
            if conversation_with:
                result_text += f"ëŒ€í™” í•„í„°: {', '.join(conversation_with)}\n"
            if sender_address:
                result_text += f"ë°œì‹ ì í•„í„°: {sender_address}\n"
            if recipient_address:
                result_text += f"ìˆ˜ì‹ ì í•„í„°: {recipient_address}\n"
            if subject_contains:
                result_text += f"ì œëª© í•„í„°: '{subject_contains}' í¬í•¨\n"
                
            # Filter messages for conversation_with or recipient_address
            if conversation_with or recipient_address:
                filtered_messages = []
                conversation_emails = [email.lower() for email in conversation_with]
                
                for mail in response.messages:
                    include_mail = False
                    
                    # Get sender email
                    sender_email = ""
                    if mail.from_address and isinstance(mail.from_address, dict):
                        email_addr = mail.from_address.get("emailAddress", {})
                        sender_email = email_addr.get("address", "").lower()
                    
                    # For conversation_with filter
                    if conversation_with:
                        # Check if sender is in conversation_with
                        if sender_email in conversation_emails:
                            include_mail = True
                        
                        # Check if this is a sent mail (from the user)
                        elif sender_email and f"{user_id}@" in sender_email:
                            # This is a sent mail, check recipients
                            if hasattr(mail, 'to_recipients') and mail.to_recipients:
                                for recipient in mail.to_recipients:
                                    if isinstance(recipient, dict):
                                        recip_addr = recipient.get("emailAddress", {})
                                        if isinstance(recip_addr, dict):
                                            recip_email = recip_addr.get("address", "").lower()
                                            if recip_email in conversation_emails:
                                                include_mail = True
                                                break
                    
                    # For recipient_address filter (only sent mails)
                    elif recipient_address:
                        # Only include if this is a sent mail from the user
                        if sender_email and f"{user_id}@" in sender_email:
                            # Check recipients
                            if hasattr(mail, 'to_recipients') and mail.to_recipients:
                                for recipient in mail.to_recipients:
                                    if isinstance(recipient, dict):
                                        recip_addr = recipient.get("emailAddress", {})
                                        if isinstance(recip_addr, dict):
                                            recip_email = recip_addr.get("address", "").lower()
                                            if recip_email == recipient_address.lower():
                                                include_mail = True
                                                break
                    
                    if include_mail:
                        filtered_messages.append(mail)
                
                # Update response with filtered messages
                response.messages = filtered_messages[:max_mails]  # Limit to requested max
                actual_total = len(filtered_messages)
                result_text += f"ì´ ë©”ì¼ ìˆ˜: {len(response.messages)}ê°œ (ì „ì²´ {actual_total}ê°œ ì¤‘)\n\n"
            else:
                result_text += f"ì´ ë©”ì¼ ìˆ˜: {response.total_fetched}ê°œ\n\n"

            # Process each mail
            blocked_senders = ["block@krs.co.kr"]  # ì°¨ë‹¨í•  ë°œì‹ ì ëª©ë¡
            processed_mails = []  # CSVë¥¼ ìœ„í•œ ë©”ì¼ ì •ë³´ ìˆ˜ì§‘

            for i, mail in enumerate(response.messages, 1):
                # Extract sender info
                sender = "Unknown"
                sender_email = None
                if mail.from_address and isinstance(mail.from_address, dict):
                    email_addr = mail.from_address.get("emailAddress", {})
                    sender_email = email_addr.get("address", "Unknown")
                    sender = sender_email
                    sender_name = email_addr.get("name", "")
                    if sender_name:
                        sender = f"{sender_name} <{sender_email}>"

                # ì°¨ë‹¨ëœ ë°œì‹ ìì¸ ê²½ìš° ìŠ¤í‚µ
                if sender_email and sender_email.lower() in [
                    s.lower() for s in blocked_senders
                ]:
                    continue

                # Save email if requested
                if save_emails:
                    try:
                        # Convert mail to dict format
                        mail_dict = (
                            mail.model_dump()
                            if hasattr(mail, "model_dump")
                            else mail.__dict__
                        )

                        # Field name mapping (Graph API -> email_saver format)
                        if "receivedDateTime" in mail_dict:
                            mail_dict["received_date_time"] = mail_dict.get(
                                "receivedDateTime"
                            )
                        if "from" in mail_dict:
                            mail_dict["from_address"] = mail_dict.get("from")
                        if "toRecipients" in mail_dict:
                            mail_dict["to_recipients"] = mail_dict.get("toRecipients")
                        if "isRead" in mail_dict:
                            mail_dict["is_read"] = mail_dict.get("isRead")
                        if "hasAttachments" in mail_dict:
                            mail_dict["has_attachments"] = mail_dict.get(
                                "hasAttachments"
                            )
                        if "bodyPreview" in mail_dict:
                            mail_dict["body_preview"] = mail_dict.get("bodyPreview")
                        if "webLink" in mail_dict:
                            mail_dict["web_link"] = mail_dict.get("webLink")

                        saved_result = await self.email_saver.save_email_as_text(
                            mail_dict,
                            user_id,
                            include_headers=True,
                            save_html=include_body,
                            upload_to_onedrive=False,
                            graph_client=None,
                        )

                        mail_saved_path = str(saved_result["text_file"])
                    except Exception as e:
                        logger.error(f"Failed to save email: {str(e)}")
                        mail_saved_path = None

                # Collect mail info for CSV
                mail_info = {
                    "id": mail.id,
                    "subject": mail.subject,
                    "sender": sender,
                    "sender_email": sender_email or "unknown@email.com",
                    "received_date": mail.received_date_time.strftime("%Y-%m-%d %H:%M"),
                    "received_date_time": mail.received_date_time,
                    "has_attachments": mail.has_attachments,
                    "is_read": mail.is_read,
                    "importance": mail.importance,
                    "attachments": [],
                }

                # Add body content to mail_info if available
                if include_body and mail.body:
                    content_type = mail.body.get("contentType", "text")
                    content = mail.body.get("content", "")

                    if content_type.lower() == "html":
                        # Simple HTML stripping
                        import re

                        text_content = re.sub("<[^<]+?>", "", content)
                        text_content = text_content.replace("&nbsp;", " ")
                        text_content = text_content.replace("&lt;", "<")
                        text_content = text_content.replace("&gt;", ">")
                        text_content = text_content.replace("&amp;", "&")
                        mail_info["body"] = text_content
                    else:
                        mail_info["body"] = content
                elif mail.body_preview:
                    mail_info["body_preview"] = mail.body_preview

                # Format mail info
                result_text += f"\n[{i}] {mail.subject}\n"
                result_text += f"   ë°œì‹ ì: {sender}\n"
                result_text += (
                    f"   ìˆ˜ì‹ ì¼: {mail.received_date_time.strftime('%Y-%m-%d %H:%M')}\n"
                )
                result_text += f"   ì½ìŒ: {'âœ“' if mail.is_read else 'âœ—'}\n"
                result_text += f"   ì²¨ë¶€: {'ğŸ“' if mail.has_attachments else '-'}\n"
                if save_emails and mail_saved_path:
                    result_text += f"   ğŸ’¾ ì €ì¥ë¨: {mail_saved_path}\n"

                # Include body if requested
                if include_body and mail.body:
                    content = mail.body.get("content", "")
                    if mail.body.get("contentType") == "html":
                        # Simple HTML stripping
                        import re

                        content = re.sub("<[^<]+?>", "", content)
                        content = (
                            content.replace("&nbsp;", " ")
                            .replace("&lt;", "<")
                            .replace("&gt;", ">")
                        )
                    result_text += (
                        f"   ë³¸ë¬¸:\n{content[:500]}...\n"
                        if len(content) > 500
                        else f"   ë³¸ë¬¸:\n{content}\n"
                    )

                # Process attachments
                if (
                    download_attachments
                    and mail.has_attachments
                    and hasattr(mail, "attachments")
                    and mail.attachments
                ):
                    result_text += f"\n   ğŸ“ ì²¨ë¶€íŒŒì¼:\n"

                    for attachment in mail.attachments:
                        att_name = attachment.get("name", "unknown")
                        att_size = attachment.get("size", 0)
                        result_text += f"      - {att_name} ({att_size:,} bytes)\n"

                        # Add attachment info to mail_info
                        attachment_info = {"name": att_name, "size": att_size}

                        # Download and convert
                        if graph_client:
                            try:
                                # Download attachment
                                file_path = (
                                    await self.attachment_downloader.download_and_save(
                                        graph_client,
                                        mail.id,
                                        attachment,
                                        user_id,
                                        email_subject=mail.subject,
                                        email_date=mail.received_date_time,
                                        sender_email=sender_email,
                                    )
                                )

                                if file_path:
                                    result_text += f"        âœ… ë‹¤ìš´ë¡œë“œ: {file_path['file_path']}\n"
                                    attachment_info["file_path"] = str(
                                        file_path["file_path"]
                                    )

                                    # Convert to text if supported
                                    if self.file_converter.is_supported(
                                        file_path["file_path"]
                                    ):
                                        text_content = (
                                            self.file_converter.convert_to_text(
                                                file_path["file_path"]
                                            )
                                        )
                                        text_file = self.file_converter.save_as_text(
                                            file_path["file_path"],
                                            text_content,
                                            att_name,
                                        )
                                        result_text += (
                                            f"        ğŸ“„ í…ìŠ¤íŠ¸ ë³€í™˜: {text_file}\n"
                                        )
                                        attachment_info["text_path"] = str(text_file)

                                        # Include full text content
                                        attachment_info["text_content"] = text_content

                                        # Include preview
                                        preview = (
                                            text_content[:3000] + "..."
                                            if len(text_content) > 3000
                                            else text_content
                                        )
                                        result_text += f"        ë¯¸ë¦¬ë³´ê¸°: {preview}\n"
                                        attachment_info["text_preview"] = preview
                                    else:
                                        result_text += (
                                            f"        âš ï¸  ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹\n"
                                        )

                            except Exception as e:
                                result_text += f"        âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\n"

                        # Add attachment info to mail_info
                        mail_info["attachments"].append(attachment_info)

                # Add mail_info to processed_mails list
                processed_mails.append(mail_info)

                result_text += "\n" + "-" * 60 + "\n"

            # CSVë¡œ ë©”ì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            if save_csv and processed_mails:
                try:
                    csv_file = self.save_emails_to_csv(processed_mails, user_id)
                    result_text += f"\nğŸ“Š ë©”ì¼ ë©”íƒ€ë°ì´í„° CSV ì €ì¥ ì™„ë£Œ: {csv_file}\n"
                except Exception as e:
                    logger.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                    result_text += f"\nâŒ CSV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n"

            # í¬ë§·íŒ… ì§€ì¹¨ ì¶”ê°€ - format_email_results í”„ë¡¬í”„íŠ¸ì™€ ë™ì¼í•œ í˜•ì‹ ì‚¬ìš©
            result_text += "\n\n" + "=" * 60 + "\n"
            result_text += "ğŸ“§ ì´ë©”ì¼ ì¡°íšŒ ê²°ê³¼ í¬ë§·íŒ… ì§€ì¹¨\n"
            result_text += "=" * 60 + "\n"
            result_text += f"""
ì¡°íšŒ ì‚¬ìš©ì: {user_id}

ë‹¤ìŒ ìˆœì„œì™€ í˜•ì‹ìœ¼ë¡œ í…Œì´ë¸”ì„ ì‘ì„±í•˜ì„¸ìš”:
**ëª¨ë“  ì†¡ìˆ˜ì‹  ë©”ì¼ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ì„œ ì‘ì„±í•´ ì£¼ì„¸ìš”**
**ëª¨ë“  ì†¡ìˆ˜ì‹  ë©”ì¼ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ì„œ ì‘ì„±í•´ ì£¼ì„¸ìš”**

**ğŸ“Š í‘œ êµ¬ì„± (í•„ìˆ˜ ì—´)**:
| ìœ í˜• | ë‚ ì§œ | ë°œì‹ ì/ìˆ˜ì‹ ì | ì œëª© | ì£¼ìš”ë‚´ìš© | ì‘ë‹µí•„ìš”ì„± | ì‘ë‹µê¸°í•œ | ì²¨ë¶€ |

**ê° ì—´ ì‘ì„± ì§€ì¹¨**:
1. **ìœ í˜•**: 
   - ğŸ“¥ ë°›ì€ë©”ì¼: ë°œì‹ ì ì´ë©”ì¼ì´ ì¡°íšŒ ì‚¬ìš©ì({user_id})ì™€ ë‹¤ë¥¸ ê²½ìš°
   - ğŸ“¨ ë³´ë‚¸ë©”ì¼: ë°œì‹ ì ì´ë©”ì¼ì´ ì¡°íšŒ ì‚¬ìš©ì({user_id})ì™€ ê°™ì€ ê²½ìš°
2. **ë‚ ì§œ**: YYYY-MM-DD HH:MM í˜•ì‹
3. **ë°œì‹ ì/ìˆ˜ì‹ ì**: 
   - ë°›ì€ë©”ì¼: ë°œì‹ ì ì´ë¦„ (ì´ë©”ì¼)
   - ë³´ë‚¸ë©”ì¼: â†’ ìˆ˜ì‹ ì ì´ë¦„ (ì´ë©”ì¼)
4. **ì œëª©**: ì „ì²´ ì œëª© (ë„ˆë¬´ ê¸¸ë©´ ... ì‚¬ìš©)
5. **ì£¼ìš”ë‚´ìš©**: í•µì‹¬ ë‚´ìš© 1-2ì¤„ ìš”ì•½
6. **ì‘ë‹µí•„ìš”ì„±**: 
   - ë°›ì€ë©”ì¼: ğŸ”´ ì¤‘ìš” (ì‘ë‹µ í•„ìš”) / ğŸŸ¢ ì¼ë°˜ (ì°¸ê³ ìš©)
   - ë³´ë‚¸ë©”ì¼: âœ… ë°œì†¡ì™„ë£Œ / â³ ì‘ë‹µëŒ€ê¸°
7. **ì‘ë‹µê¸°í•œ**: êµ¬ì²´ì  ë‚ ì§œ ë˜ëŠ” "ì¦‰ì‹œ", "3ì¼ ë‚´", "ì—†ìŒ" ë“±
8. **ì²¨ë¶€**: íŒŒì¼ëª… (íŒŒì¼í˜•ì‹) ë˜ëŠ” "ì—†ìŒ"

**ì‘ë‹µ í•„ìš”ì„± íŒë‹¨ ê¸°ì¤€**:
- ì§ˆë¬¸ì´ í¬í•¨ëœ ê²½ìš°
- "íšŒì‹  ìš”ì²­", "ë‹µë³€ ë¶€íƒ" ë“±ì˜ í‘œí˜„
- ë§ˆê°ì¼ì´ ëª…ì‹œëœ ê²½ìš°
- ìŠ¹ì¸/ê²€í†  ìš”ì²­ì´ ìˆëŠ” ê²½ìš°

**ì˜ˆì‹œ**:
| ğŸ“¥ | 2024-01-15 09:30 | ê¹€ì² ìˆ˜ (kim@company.com) | í”„ë¡œì íŠ¸ ì§„í–‰ í˜„í™© ë³´ê³  | Q1 ëª©í‘œ ë‹¬ì„±ë¥  85%, ì¶”ê°€ ì˜ˆì‚° ìŠ¹ì¸ ìš”ì²­ | ğŸ”´ ì¤‘ìš” | 1/17ê¹Œì§€ | ë³´ê³ ì„œ.pdf |
| ğŸ“¤ | 2024-01-15 11:20 | â†’ ì´ì˜í¬ (lee@company.com) | Re: í”„ë¡œì íŠ¸ ì§„í–‰ í˜„í™© ë³´ê³  | ì˜ˆì‚° ìŠ¹ì¸ ì™„ë£Œ, ì§„í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤ | âœ… ë°œì†¡ì™„ë£Œ | - | ì—†ìŒ |

ì´ë©”ì¼ ë‚´ìš©ê³¼ ì²¨ë¶€íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì‘ë‹µ í•„ìš”ì„±ê³¼ ê¸°í•œì„ ì •í™•íˆ íŒë‹¨í•˜ì„¸ìš”.
"""

            # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë“¤ ì‚­ì œ
            try:
                import shutil

                user_dir = Path(self.attachment_downloader.output_dir) / user_id
                if user_dir.exists():
                    shutil.rmtree(user_dir)
                    logger.info(f"âœ… ì‚¬ìš©ì ë””ë ‰í† ë¦¬ ì‚­ì œ ì™„ë£Œ: {user_dir}")
            except Exception as e:
                logger.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

            return result_text

        except Exception as e:
            logger.error(f"Mail query error: {str(e)}", exc_info=True)
            return f"âŒ ë©”ì¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

    async def _handle_list_accounts(self) -> str:
        """List active email accounts"""
        try:
            query = """
                SELECT 
                    user_id, 
                    user_name, 
                    email,
                    is_active,
                    status,
                    last_sync_time
                FROM accounts 
                WHERE is_active = 1
                ORDER BY user_id
            """
            accounts = self.db.fetch_all(query)

            result_text = "ğŸ‘¥ í™œì„± ì´ë©”ì¼ ê³„ì • ëª©ë¡\n"
            result_text += "=" * 60 + "\n\n"

            for account in accounts:
                result_text += f"â€¢ {account['user_id']}"
                if account["user_name"]:
                    result_text += f" ({account['user_name']})"
                if account["email"]:
                    result_text += f" - {account['email']}"
                result_text += f"\n  ìƒíƒœ: {account['status']}"
                if account["last_sync_time"]:
                    result_text += f", ë§ˆì§€ë§‰ ë™ê¸°í™”: {account['last_sync_time']}"
                result_text += "\n\n"

            result_text += f"\nì´ {len(accounts)}ê°œ ê³„ì •"

            return result_text

        except Exception as e:
            logger.error(f"List accounts error: {str(e)}", exc_info=True)
            return f"âŒ ê³„ì • ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

    def save_emails_to_csv(self, emails: List[Dict[str, Any]], user_id: str) -> Path:
        """Save email metadata to CSV file"""
        # CSV file path
        csv_dir = Path(self.attachment_downloader.output_dir) / user_id
        csv_dir.mkdir(parents=True, exist_ok=True)

        # Include timestamp in filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = csv_dir / f"email_metadata_{timestamp}.csv"

        # Write CSV
        with open(csv_file, "w", newline="", encoding="utf-8-sig") as f:
            # UTF-8 BOM for Korean characters in Excel
            fieldnames = [
                "ë²ˆí˜¸",
                "ì œëª©",
                "ë°œì‹ ì",
                "ë°œì‹ ì_ì´ë©”ì¼",
                "ìˆ˜ì‹ ì¼ì‹œ",
                "ì½ìŒìƒíƒœ",
                "ì¤‘ìš”ë„",
                "ì²¨ë¶€íŒŒì¼",
                "ì²¨ë¶€íŒŒì¼_ê°œìˆ˜",
                "ì²¨ë¶€íŒŒì¼_ëª©ë¡",
                "ë³¸ë¬¸_ë¯¸ë¦¬ë³´ê¸°",
                "í´ë”ëª…",
                "message_id",
            ]

            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for idx, email in enumerate(emails, 1):
                # Process attachment info
                attachment_names = []
                attachment_count = 0
                if email.get("attachments"):
                    attachment_names = [att["name"] for att in email["attachments"]]
                    attachment_count = len(attachment_names)

                # Generate folder name (same as actual save folder)
                safe_subject = self.attachment_downloader._sanitize_filename(
                    email.get("subject", "NoSubject")[:50]
                )
                received_datetime = email.get("received_date_time", datetime.now())
                date_str = (
                    received_datetime.strftime("%Y%m%d_%H%M%S")
                    if isinstance(received_datetime, datetime)
                    else datetime.now().strftime("%Y%m%d_%H%M%S")
                )
                safe_sender = self.attachment_downloader._sanitize_filename(
                    email.get("sender_email", "unknown")
                )  # Use full email
                folder_name = f"{safe_subject}_{date_str}_{safe_sender}"

                # Get body preview
                body_preview = ""
                if "body" in email:
                    body_preview = (
                        email["body"][:100].replace("\n", " ").replace("\r", " ")
                    )
                elif "body_preview" in email:
                    body_preview = (
                        email["body_preview"][:100]
                        .replace("\n", " ")
                        .replace("\r", " ")
                    )

                row = {
                    "ë²ˆí˜¸": idx,
                    "ì œëª©": email.get("subject", ""),
                    "ë°œì‹ ì": email.get("sender", ""),
                    "ë°œì‹ ì_ì´ë©”ì¼": email.get("sender_email", ""),
                    "ìˆ˜ì‹ ì¼ì‹œ": email.get("received_date", ""),
                    "ì½ìŒìƒíƒœ": "ì½ìŒ" if email.get("is_read", False) else "ì•ˆì½ìŒ",
                    "ì¤‘ìš”ë„": email.get("importance", "normal"),
                    "ì²¨ë¶€íŒŒì¼": (
                        "ìˆìŒ" if email.get("has_attachments", False) else "ì—†ìŒ"
                    ),
                    "ì²¨ë¶€íŒŒì¼_ê°œìˆ˜": attachment_count,
                    "ì²¨ë¶€íŒŒì¼_ëª©ë¡": (
                        "; ".join(attachment_names) if attachment_names else ""
                    ),
                    "ë³¸ë¬¸_ë¯¸ë¦¬ë³´ê¸°": body_preview,
                    "í´ë”ëª…": folder_name,
                    "message_id": email.get("id", ""),
                }

                writer.writerow(row)

        logger.info(f"Email metadata CSV saved: {csv_file}")
        return csv_file

    async def _handle_file_conversion(self, arguments: Dict[str, Any]) -> str:
        """Convert file to text"""
        try:
            file_path = Path(arguments.get("file_path", ""))

            if not file_path.exists():
                return f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"

            if not self.file_converter.is_supported(file_path):
                return f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path.suffix}"

            # Convert to text
            text_content = self.file_converter.convert_to_text(file_path)

            # Save as text file
            text_file = self.file_converter.save_as_text(file_path, text_content)

            result_text = f"ğŸ“„ íŒŒì¼ ë³€í™˜ ì™„ë£Œ\n"
            result_text += f"{'='*60}\n"
            result_text += f"ì›ë³¸ íŒŒì¼: {file_path}\n"
            result_text += f"í…ìŠ¤íŠ¸ íŒŒì¼: {text_file}\n"
            result_text += f"íŒŒì¼ í¬ê¸°: {len(text_content):,} ê¸€ì\n\n"
            result_text += f"ë‚´ìš©:\n{'-'*60}\n"
            result_text += text_content

            return result_text

        except Exception as e:
            logger.error(f"File conversion error: {str(e)}", exc_info=True)
            return f"âŒ íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {str(e)}"

    async def _send_list_changed_notifications(self, request: Request):
        """Send list changed notifications after initialization"""
        # Wait a bit to ensure client is ready
        await asyncio.sleep(0.1)

        # Note: In a real implementation, we would need to track the client's SSE connection
        # For now, we'll just log that we would send these
        logger.info("ğŸ“¤ Would send notifications/tools/list_changed")
        logger.info("ğŸ“¤ Would send notifications/prompts/list_changed")
        logger.info("ğŸ“¤ Would send notifications/resources/list_changed")

    async def _handle_streaming_request(self, request: Request):
        """Handle MCP request - returns single JSON response"""
        # Common headers
        base_headers = {
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS, DELETE",
            "Access-Control-Allow-Headers": "Content-Type, Authorization, Mcp-Session-Id, MCP-Protocol-Version",
            "Access-Control-Expose-Headers": "Mcp-Session-Id",
        }

        # Read and parse request
        try:
            body = await request.body()
            if not body:
                return JSONResponse(
                    {
                        "jsonrpc": "2.0",
                        "error": {"code": -32700, "message": "Empty request body"},
                    },
                    status_code=400,
                    headers=base_headers,
                )

            try:
                rpc_request = json.loads(body)
            except json.JSONDecodeError as e:
                return JSONResponse(
                    {
                        "jsonrpc": "2.0",
                        "error": {"code": -32700, "message": f"Parse error: {str(e)}"},
                    },
                    status_code=400,
                    headers=base_headers,
                )
        except Exception as e:
            return JSONResponse(
                {
                    "jsonrpc": "2.0",
                    "error": {"code": -32603, "message": f"Internal error: {str(e)}"},
                },
                status_code=500,
                headers=base_headers,
            )

        # Extract request details
        method = rpc_request.get("method")
        params = rpc_request.get("params", {}) or {}
        request_id = rpc_request.get("id")

        logger.info(f"ğŸ“¨ Received RPC request: {method} with id: {request_id}")

        # Handle notification (no id) - return 202 with no body
        if request_id is None:
            logger.info(f"ğŸ“¤ Handling notification: {method}")

            # If this is the initialized notification, send list changed notifications
            if method == "notifications/initialized":
                # Send tools list changed notification after a short delay
                asyncio.create_task(self._send_list_changed_notifications(request))

            return Response(status_code=202, headers=base_headers)

        # Process based on method
        logger.info(f"ğŸ“¤ Processing method: {method} with params: {params}")

        if method == "initialize":
            # Initialize session with standard Mcp-Session-Id
            session_id = secrets.token_urlsafe(24)
            caps = self.mcp_server.get_capabilities(
                notification_options=NotificationOptions(), experimental_capabilities={}
            )

            # Fix null fields to empty objects/lists for spec compliance
            caps_dict = caps.model_dump()
            if caps_dict.get("logging") is None:
                caps_dict["logging"] = {}
            if caps_dict.get("resources") is None:
                caps_dict["resources"] = {"listChanged": False}
            # Remove completions field if it's null (not supported by this server)
            if caps_dict.get("completions") is None:
                caps_dict.pop("completions", None)

            self.sessions[session_id] = {"initialized": True, "capabilities": caps_dict}

            # Use the protocol version requested by the client
            requested_version = params.get("protocolVersion", "2025-06-18")

            # Add session header and ensure it's exposed
            headers = base_headers.copy()
            headers["Mcp-Session-Id"] = session_id
            headers["MCP-Protocol-Version"] = requested_version
            headers["Access-Control-Expose-Headers"] = (
                "Mcp-Session-Id, MCP-Protocol-Version"
            )

            response = {
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "protocolVersion": requested_version,
                    # Use fixed capabilities (with logging as empty object)
                    "capabilities": caps_dict,
                    "serverInfo": {
                        "name": "mail-attachment-server",
                        "title": "ğŸ“§ Mail Attachment Server",
                        "version": "2.0.0",
                        "description": "MCP server for email attachment handling",
                    },
                    "instructions": "ì´ë©”ì¼ê³¼ ì²¨ë¶€íŒŒì¼ì„ ì¡°íšŒí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” MCP ì„œë²„ì…ë‹ˆë‹¤.",
                },
            }
            logger.info(
                f"ğŸ“¤ Sending initialize response: {json.dumps(response, indent=2)}"
            )
            return JSONResponse(response, headers=headers)

        elif method == "tools/list":
            # List tools
            if "list_tools" in self._handlers:
                tools = await self._handlers["list_tools"]()
            else:
                tools = []

            # Clean up tool data - remove null fields
            tools_data = []
            for tool in tools:
                tool_dict = tool.model_dump()
                # Remove null fields as per spec
                cleaned_tool = {}
                for key, value in tool_dict.items():
                    if value is not None:
                        cleaned_tool[key] = value
                tools_data.append(cleaned_tool)

            # Debug: Log the actual tool data being sent
            logger.info(f"ğŸ“¤ Tool data details: {json.dumps(tools_data, indent=2)}")

            logger.info(
                f"ğŸ“¤ Returning {len(tools_data)} tools: {[t['name'] for t in tools_data]}"
            )

            response = {
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {"tools": tools_data},
            }
            return JSONResponse(response, headers=base_headers)

        elif method == "tools/call":
            # Call tool
            tool_name = params.get("name")
            tool_args = params.get("arguments", {})

            logger.info(f"ğŸ”§ [MCP Server] Received tools/call request")
            logger.info(f"  â€¢ Tool: {tool_name}")
            logger.info(
                f"  â€¢ Arguments: {json.dumps(tool_args, indent=2, ensure_ascii=False)}"
            )

            try:
                if "call_tool" in self._handlers:
                    results = await self._handlers["call_tool"](tool_name, tool_args)
                else:
                    raise ValueError("Tool handler not available")

                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [content.model_dump() for content in results]
                    },
                }
            except Exception as e:
                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "error": {"code": -32603, "message": str(e)},
                }

            return JSONResponse(response, headers=base_headers)

        elif method == "prompts/list":
            # List prompts
            if "list_prompts" in self._handlers:
                prompts = await self._handlers["list_prompts"]()
            else:
                prompts = []

            response = {
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {"prompts": [prompt.model_dump() for prompt in prompts]},
            }
            return JSONResponse(response, headers=base_headers)

        elif method == "resources/list":
            # Resources not supported, return empty list
            response = {"jsonrpc": "2.0", "id": request_id, "result": {"resources": []}}
            return JSONResponse(response, headers=base_headers)

        elif method == "prompts/get":
            # Get prompt
            prompt_name = params.get("name")
            prompt_args = params.get("arguments", {})

            try:
                if "get_prompt" in self._handlers:
                    prompt_msg = await self._handlers["get_prompt"](
                        prompt_name, prompt_args
                    )
                else:
                    raise ValueError("Prompt handler not available")

                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {"messages": [prompt_msg.model_dump()]},
                }
            except Exception as e:
                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "error": {"code": -32603, "message": str(e)},
                }

            return JSONResponse(response, headers=base_headers)

        else:
            # Unknown method
            response = {
                "jsonrpc": "2.0",
                "id": request_id,
                "error": {"code": -32601, "message": f"Method not found: {method}"},
            }
            return JSONResponse(response, status_code=404, headers=base_headers)

    def _create_app(self):
        """Create Starlette application"""

        async def health_check(request):
            """Health check endpoint"""
            return JSONResponse(
                {
                    "status": "healthy",
                    "server": "mail-attachment-server",
                    "version": "2.0.0",
                    "transport": "http-streaming",
                },
                headers={
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
                    "Access-Control-Allow-Headers": "Content-Type, Mcp-Session-Id, MCP-Protocol-Version",
                    "Access-Control-Expose-Headers": "Mcp-Session-Id",
                },
            )

        async def server_info(request):
            """Server information endpoint"""
            return JSONResponse(
                {
                    "name": "mail-attachment-server",
                    "version": "2.0.0",
                    "protocol": "mcp",
                    "transport": "http-streaming",
                    "endpoints": {
                        "streaming": "/stream",
                        "health": "/health",
                        "info": "/info",
                    },
                }
            )

        # OPTIONS handler for CORS preflight
        async def options_handler(request):
            return Response(
                "",
                headers={
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "GET, POST, OPTIONS, DELETE",
                    "Access-Control-Allow-Headers": "Content-Type, Mcp-Session-Id, Authorization, MCP-Protocol-Version",
                    "Access-Control-Expose-Headers": "Mcp-Session-Id",
                    "Access-Control-Max-Age": "3600",
                },
            )

        # Root endpoint handler
        async def root_handler(request):
            """Handle root endpoint requests"""
            if request.method == "POST":
                # For POST requests, handle as MCP request
                return await self._handle_streaming_request(request)
            else:
                # For GET/HEAD requests, return server info
                return JSONResponse(
                    {
                        "name": "mail-attachment-server",
                        "version": "2.0.0",
                        "protocol": "mcp",
                        "transport": "http",
                        "endpoints": {"mcp": "/", "health": "/health", "info": "/info"},
                    },
                    headers={
                        "Access-Control-Allow-Origin": "*",
                        "Access-Control-Allow-Methods": "GET, POST, OPTIONS, HEAD, DELETE",
                        "Access-Control-Allow-Headers": "Content-Type, Mcp-Session-Id, Authorization, MCP-Protocol-Version",
                        "Access-Control-Expose-Headers": "Mcp-Session-Id",
                    },
                )

        # Register endpoint - for client registration
        async def register_handler(request):
            """Handle client registration"""
            return JSONResponse(
                {
                    "success": True,
                    "message": "No registration required - this is an open server",
                    "endpoint": "/stream",
                },
                headers={
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "POST, OPTIONS",
                    "Access-Control-Allow-Headers": "Content-Type",
                },
            )

        # OAuth discovery endpoints - indicate no auth required
        async def oauth_authorization_server(request):
            """OAuth authorization server metadata - returns empty to indicate no auth"""
            # Return 404 to indicate OAuth is not supported
            return JSONResponse(
                {
                    "error": "OAuth not supported - this server does not require authentication"
                },
                status_code=404,
                headers={
                    "Access-Control-Allow-Origin": "*",
                    "Content-Type": "application/json",
                },
            )

        async def oauth_protected_resource(request):
            """OAuth protected resource metadata - returns empty to indicate no auth"""
            # Return 404 to indicate this resource is not OAuth protected
            return JSONResponse(
                {"error": "This resource does not require authentication"},
                status_code=404,
                headers={
                    "Access-Control-Allow-Origin": "*",
                    "Content-Type": "application/json",
                },
            )

        # Create routes
        routes = [
            # Root endpoint
            Route("/", endpoint=root_handler, methods=["GET", "POST", "HEAD"]),
            Route("/", endpoint=options_handler, methods=["OPTIONS"]),
            # MCP endpoint (alias for root)
            Route("/mcp", endpoint=self._handle_streaming_request, methods=["POST"]),
            Route("/mcp", endpoint=options_handler, methods=["OPTIONS"]),
            # Register endpoint
            Route("/register", endpoint=register_handler, methods=["POST"]),
            Route("/register", endpoint=options_handler, methods=["OPTIONS"]),
            # Health and info endpoints
            Route("/health", endpoint=health_check, methods=["GET"]),
            Route("/info", endpoint=server_info, methods=["GET"]),
            # Streaming endpoints (both /stream and /steam for compatibility)
            Route("/stream", endpoint=self._handle_streaming_request, methods=["POST"]),
            Route(
                "/steam",
                endpoint=self._handle_streaming_request,
                methods=["POST", "GET", "HEAD"],
            ),
            Route("/stream", endpoint=options_handler, methods=["OPTIONS"]),
            Route("/steam", endpoint=options_handler, methods=["OPTIONS"]),
            Route("/health", endpoint=options_handler, methods=["OPTIONS"]),
            Route("/info", endpoint=options_handler, methods=["OPTIONS"]),
            # OAuth discovery endpoints
            Route(
                "/.well-known/oauth-authorization-server",
                endpoint=oauth_authorization_server,
                methods=["GET"],
            ),
            Route(
                "/.well-known/oauth-protected-resource",
                endpoint=oauth_protected_resource,
                methods=["GET"],
            ),
            Route(
                "/.well-known/oauth-authorization-server/stream",
                endpoint=oauth_authorization_server,
                methods=["GET"],
            ),
            Route(
                "/.well-known/oauth-protected-resource/stream",
                endpoint=oauth_protected_resource,
                methods=["GET"],
            ),
            Route(
                "/.well-known/oauth-authorization-server/steam",
                endpoint=oauth_authorization_server,
                methods=["GET"],
            ),
            Route(
                "/.well-known/oauth-protected-resource/steam",
                endpoint=oauth_protected_resource,
                methods=["GET"],
            ),
        ]

        return Starlette(routes=routes)

    def run(self):
        """Run the HTTP streaming MCP server"""
        logger.info(
            f"ğŸš€ Starting HTTP Streaming Mail Attachment Server on http://{self.host}:{self.port}"
        )
        logger.info(f"ğŸ“§ Streaming endpoint: http://{self.host}:{self.port}/stream")
        logger.info(f"ğŸ’š Health check: http://{self.host}:{self.port}/health")
        logger.info(f"â„¹ï¸  Server info: http://{self.host}:{self.port}/info")

        # Run uvicorn
        uvicorn.run(self.app, host=self.host, port=self.port, log_level="info")


def main():
    """Main entry point"""
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler("mcp_mail_attachment_server.log"),
        ],
    )

    # Get configuration from environment or use defaults
    server = HTTPStreamingMailAttachmentServer(
        host=os.getenv("MCP_HOST", "0.0.0.0"), port=int(os.getenv("MCP_PORT", "8002"))
    )

    # Run the server
    server.run()


if __name__ == "__main__":
    main()
