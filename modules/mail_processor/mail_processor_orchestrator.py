"""Mail Processor ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì™„ì „ ë…ë¦½ì  êµ¬í˜„"""
import time
from datetime import datetime
from typing import List, Dict

from infra.core.logger import get_logger
from .mail_processor_schema import (
    MailProcessingResult, ProcessedMailData, ProcessingStatus, GraphMailItem
)
from .keyword_extractor_service import MailProcessorKeywordExtractorService
from .mail_filter_service import MailProcessorFilterService
from ._mail_processor_helpers import (
    MailProcessorGraphApiHelper,
    MailProcessorDatabaseHelper,
    MailProcessorKafkaHelper,
    MailProcessorDataHelper
)


class MailProcessorOrchestrator:
    """ë©”ì¼ ì²˜ë¦¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì™„ì „ ë…ë¦½ì  êµ¬í˜„"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.filter_service = MailProcessorFilterService()
        self.keyword_service = MailProcessorKeywordExtractorService()
        
        # í—¬í¼ ì´ˆê¸°í™”
        self.graph_helper = MailProcessorGraphApiHelper()
        self.db_helper = MailProcessorDatabaseHelper()
        self.kafka_helper = MailProcessorKafkaHelper()
        
    async def process_new_mails(self) -> MailProcessingResult:
        """ìƒˆ ë©”ì¼ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        start_time = time.time()
        total_processed = 0
        total_skipped = 0
        total_failed = 0
        errors = []
        
        try:
            # 1. í™œì„± ê³„ì • ì¡°íšŒ
            active_accounts = await self.db_helper.get_active_accounts()
            self.logger.info(f"í™œì„± ê³„ì • {len(active_accounts)}ê°œ ì²˜ë¦¬ ì‹œì‘")
            
            for account in active_accounts:
                try:
                    # 2. ê³„ì •ë³„ ë©”ì¼ ì²˜ë¦¬
                    result = await self._process_account_mails(account)
                    total_processed += result.processed_count
                    total_skipped += result.skipped_count
                    total_failed += result.failed_count
                    
                    if result.errors:
                        errors.extend(result.errors)
                    
                except Exception as e:
                    error_msg = f"ê³„ì • {account['user_id']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                    self.logger.error(error_msg, exc_info=True)
                    errors.append(error_msg)
                    total_failed += 1
                    
                    # ê³„ì •ë³„ ì—ëŸ¬ ê¸°ë¡
                    await self.db_helper.handle_account_error(account['user_id'], str(e))
            
            execution_time = int((time.time() - start_time) * 1000)
            
            return MailProcessingResult(
                account_id="ALL",
                total_fetched=total_processed + total_skipped,
                processed_count=total_processed,
                skipped_count=total_skipped,
                failed_count=total_failed,
                last_sync_time=datetime.now(),
                execution_time_ms=execution_time,
                errors=errors
            )
            
        except Exception as e:
            self.logger.error(f"ë©”ì¼ ì²˜ë¦¬ ì „ì²´ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
    
    async def _process_account_mails(self, account: Dict) -> MailProcessingResult:
        """ê³„ì •ë³„ ë©”ì¼ ì²˜ë¦¬"""
        account_start_time = time.time()
        processed_count = 0
        skipped_count = 0
        failed_count = 0
        errors = []
        
        try:
            # 1. Graph APIì—ì„œ ë©”ì¼ ì¡°íšŒ
            mails = await self.graph_helper.fetch_mails_from_graph(account)
            self.logger.info(f"ê³„ì • {account['user_id']}: {len(mails)}ê°œ ë©”ì¼ ì¡°íšŒë¨")
            
            # 2. ê° ë©”ì¼ ì²˜ë¦¬
            for mail in mails:
                try:
                    processed_mail = await self._process_single_mail(account['user_id'], mail)
                    
                    if processed_mail.processing_status == ProcessingStatus.SUCCESS:
                        # DB ì €ì¥
                        await self.db_helper.save_mail_history(processed_mail)
                        # Kafka ì´ë²¤íŠ¸ ë°œí–‰ (í‚¤ì›Œë“œ ì •ë³´ í¬í•¨)
                        await self.kafka_helper.publish_kafka_event(account['user_id'], mail, processed_mail.keywords)
                        processed_count += 1
                        
                    elif processed_mail.processing_status == ProcessingStatus.SKIPPED:
                        skipped_count += 1
                        
                    else:  # FAILED
                        failed_count += 1
                        if processed_mail.error_message:
                            errors.append(processed_mail.error_message)
                
                except Exception as e:
                    error_msg = f"ë©”ì¼ {mail.get('id', 'unknown')} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                    self.logger.error(error_msg)
                    errors.append(error_msg)
                    failed_count += 1
            
            # 3. ê³„ì • ë™ê¸°í™” ì‹œê°„ ì—…ë°ì´íŠ¸
            await self.db_helper.update_account_sync_time(account['user_id'], datetime.now())
            
            execution_time = int((time.time() - account_start_time) * 1000)
            
            self.logger.info(
                f"ê³„ì • {account['user_id']} ì²˜ë¦¬ ì™„ë£Œ: "
                f"ì²˜ë¦¬={processed_count}, ê±´ë„ˆëœ€={skipped_count}, ì‹¤íŒ¨={failed_count}"
            )
            
            return MailProcessingResult(
                account_id=account['user_id'],
                total_fetched=len(mails),
                processed_count=processed_count,
                skipped_count=skipped_count,
                failed_count=failed_count,
                last_sync_time=datetime.now(),
                execution_time_ms=execution_time,
                errors=errors
            )
            
        except Exception as e:
            self.logger.error(f"ê³„ì • {account['user_id']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _process_single_mail(self, account_id: str, mail: Dict) -> ProcessedMailData:
        """ê°œë³„ ë©”ì¼ ì²˜ë¦¬"""
        try:
            mail_id = mail.get('id', 'unknown')
            sender_info = mail.get('from', {}).get('emailAddress', {})
            sender_address = sender_info.get('address', '')
            subject = mail.get('subject', '')
            
            # 1. ë°œì‹ ì í•„í„°ë§ - ê°œì„ ëœ ë°œì‹ ì ì¶”ì¶œ ì‚¬ìš©
            sender_address = MailProcessorDataHelper._extract_sender_address(mail)
                
            if not self.filter_service.should_process(sender_address, subject):
                return MailProcessorDataHelper.create_processed_mail_data(
                    mail, account_id, [], ProcessingStatus.SKIPPED,
                    "ë°œì‹ ì í•„í„°ë§ìœ¼ë¡œ ì œì™¸"
                )
            
            # 2. ì¤‘ë³µ ê²€ì‚¬
            if await self.db_helper.is_duplicate_mail(mail_id, sender_address):
                return MailProcessorDataHelper.create_processed_mail_data(
                    mail, account_id, [], ProcessingStatus.SKIPPED,
                    "ì¤‘ë³µ ë©”ì¼"
                )
            
            # 3. í‚¤ì›Œë“œ ì¶”ì¶œ
            body_content = MailProcessorDataHelper.extract_mail_content(mail)
            keyword_response = await self.keyword_service.extract_keywords(body_content)
            
            # 4. ì²˜ë¦¬ëœ ë©”ì¼ ë°ì´í„° ìƒì„±
            return MailProcessorDataHelper.create_processed_mail_data(
                mail, account_id, keyword_response.keywords, ProcessingStatus.SUCCESS
            )
            
        except Exception as e:
            self.logger.error(f"ë©”ì¼ ì²˜ë¦¬ ì‹¤íŒ¨ - {mail.get('id', 'unknown')}: {str(e)}")
            return MailProcessorDataHelper.create_processed_mail_data(
                mail, account_id, [], ProcessingStatus.FAILED, str(e)
            )
    
    async def process_graph_mail_item(self, mail_item: GraphMailItem, account_id: str) -> ProcessedMailData:
        """GraphMailItem ê°ì²´ë¥¼ ë°›ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            # GraphMailItemì„ Dictë¡œ ë³€í™˜
            mail_dict = mail_item.model_dump()
            
            # ë°œì‹ ì ì •ë³´ ì¶”ì¶œ
            sender_address = ""
            if mail_item.from_address and isinstance(mail_item.from_address, dict):
                email_address = mail_item.from_address.get('emailAddress', {})
                sender_address = email_address.get('address', '')
            elif mail_item.sender and isinstance(mail_item.sender, dict):
                email_address = mail_item.sender.get('emailAddress', {})
                sender_address = email_address.get('address', '')
            
            # 1. ë°œì‹ ì í•„í„°ë§ - í•„í„°ë§ëœ ë©”ì¼ì€ í‚¤ì›Œë“œ ì¶”ì¶œ ì—†ì´ ë°”ë¡œ SKIPPED ë°˜í™˜
            if not self.filter_service.should_process(sender_address, mail_item.subject or ''):
                return MailProcessorDataHelper.create_processed_mail_data(
                    mail_dict, account_id, [], ProcessingStatus.SKIPPED,
                    "ë°œì‹ ì í•„í„°ë§ìœ¼ë¡œ ì œì™¸"
                )
            
            # 2. ì¤‘ë³µ ê²€ì‚¬ - ì¤‘ë³µ ë©”ì¼ë„ í‚¤ì›Œë“œ ì¶”ì¶œ ì—†ì´ ë°”ë¡œ SKIPPED ë°˜í™˜
            if await self.db_helper.is_duplicate_mail(mail_item.id, sender_address):
                return MailProcessorDataHelper.create_processed_mail_data(
                    mail_dict, account_id, [], ProcessingStatus.SKIPPED,
                    "ì¤‘ë³µ ë©”ì¼"
                )
            
            # 3. í‚¤ì›Œë“œ ì¶”ì¶œ (í•„í„°ë§ê³¼ ì¤‘ë³µ ê²€ì‚¬ë¥¼ í†µê³¼í•œ ë©”ì¼ë§Œ)
            body_content = self._extract_content_from_graph_mail_item(mail_item)
            keyword_response = await self.keyword_service.extract_keywords(body_content)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ì •ë³´ ë¡œê¹…
            self.logger.info(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ - ë©”ì¼: {mail_item.id}")
            self.logger.info(f"ğŸ”§ [EXTRACTION] ë°©ì‹: {keyword_response.method}, ëª¨ë¸: {keyword_response.model}")
            self.logger.info(f"â±ï¸ [EXTRACTION] ì‹¤í–‰ì‹œê°„: {keyword_response.execution_time_ms}ms")
            
            if keyword_response.token_info:
                token_info = keyword_response.token_info
                self.logger.info(f"ğŸª™ [TOKEN] ì‚¬ìš©ëŸ‰: {token_info.get('total_tokens', 0)}í† í°")
                if token_info.get('cost_usd', 0) > 0:
                    self.logger.info(f"ğŸ’° [COST] ë¹„ìš©: ${token_info.get('cost_usd', 0)}")
            
            # 4. ì²˜ë¦¬ëœ ë©”ì¼ ë°ì´í„° ìƒì„±
            processed_mail = MailProcessorDataHelper.create_processed_mail_data(
                mail_dict, account_id, keyword_response.keywords, ProcessingStatus.SUCCESS
            )
            
            # 5. DB ì €ì¥
            await self.db_helper.save_mail_history(processed_mail)
            
            # 6. Kafka ì´ë²¤íŠ¸ ë°œí–‰ (í‚¤ì›Œë“œ ì •ë³´ í¬í•¨)
            await self.kafka_helper.publish_kafka_event(account_id, mail_dict, processed_mail.keywords)
            
            self.logger.info(f"GraphMailItem ì²˜ë¦¬ ì™„ë£Œ: {mail_item.id}")
            return processed_mail
            
        except Exception as e:
            self.logger.error(f"GraphMailItem ì²˜ë¦¬ ì‹¤íŒ¨ - {mail_item.id}: {str(e)}")
            return MailProcessorDataHelper.create_processed_mail_data(
                mail_item.model_dump(), account_id, [], ProcessingStatus.FAILED, str(e)
            )
    
    def _extract_content_from_graph_mail_item(self, mail_item: GraphMailItem) -> str:
        """GraphMailItemì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ"""
        # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ ìš°ì„ ìˆœìœ„: body.content > body_preview > subject
        body_content = ""
        
        # 1. body.content í™•ì¸
        if mail_item.body and isinstance(mail_item.body, dict) and mail_item.body.get('content'):
            body_content = mail_item.body['content']
        
        # 2. body_preview í™•ì¸
        elif mail_item.body_preview:
            body_content = mail_item.body_preview
        
        # 3. subjectë§Œ ìˆëŠ” ê²½ìš°
        elif mail_item.subject:
            body_content = mail_item.subject
        
        return body_content
    
    async def get_processing_stats(self) -> Dict:
        """ì²˜ë¦¬ í†µê³„ ì¡°íšŒ"""
        try:
            # ìµœê·¼ ì²˜ë¦¬ í†µê³„
            query = """
                SELECT 
                    COUNT(*) as total_mails,
                    COUNT(CASE WHEN processed_at > datetime('now', '-1 hour') THEN 1 END) as recent_hour,
                    COUNT(CASE WHEN processed_at > datetime('now', '-1 day') THEN 1 END) as recent_day
                FROM mail_history
            """
            
            result = self.db_helper.db_manager.fetch_one(query)
            
            # í•„í„°ë§ í†µê³„
            filter_stats = self.filter_service.get_filter_stats()
            
            return {
                "mail_stats": dict(result) if result else {},
                "filter_stats": filter_stats,
                "services_status": {
                    "keyword_extractor": "active",
                    "mail_filter": "active",
                    "graph_api": "active",
                    "database": "active",
                    "kafka": "active"
                }
            }
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"error": str(e)}
