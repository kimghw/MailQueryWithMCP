#!/usr/bin/env python3
"""
Mail Query -> Mail Process í†µí•© í…ŒìŠ¤íŠ¸
mail_queryì—ì„œ ë©”ì¼ì„ ì¡°íšŒí•˜ê³  mail_processë¡œ ì²˜ë¦¬í•˜ëŠ” ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
"""

#uv run python script/ignore/mail_query_processor.py --clear-data
import asyncio
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import json

# ëª¨ë“ˆ ì„í¬íŠ¸
from modules.mail_query import (
    MailQueryOrchestrator,
    MailQueryRequest,
    MailQueryFilters,
    PaginationOptions
)
from modules.mail_process import (
    MailProcessorOrchestrator,
    ProcessingStatus
)
from infra.core.logger import get_logger, update_all_loggers_level
from infra.core.database import get_database_manager
import logging

# Kafka ê´€ë ¨ ë””ë²„ê¹… ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
logging.getLogger("infra.core.kafka_client").setLevel(logging.ERROR)
logging.getLogger("kafka").setLevel(logging.ERROR)
logging.getLogger("aiokafka").setLevel(logging.ERROR)

# ì „ì²´ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
update_all_loggers_level("INFO")
logger = get_logger(__name__)


class MailIntegrationTester:
    """Mail Query -> Mail Process í†µí•© í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.mail_query = MailQueryOrchestrator()
        self.mail_processor = MailProcessorOrchestrator()
        self.db_manager = get_database_manager()
    
    async def test_integration_flow(
        self, 
        user_id: str = "kimghw",
        days_back: int = 7,
        max_mails: int = 10,
        filters: Optional[MailQueryFilters] = None
    ) -> Dict:
        """
        í†µí•© í”Œë¡œìš° í…ŒìŠ¤íŠ¸
        
        Args:
            user_id: ì‚¬ìš©ì ID
            days_back: ì¡°íšŒí•  ê³¼ê±° ì¼ìˆ˜
            max_mails: ìµœëŒ€ ì²˜ë¦¬í•  ë©”ì¼ ìˆ˜
            filters: ì¶”ê°€ í•„í„° ì¡°ê±´
            
        Returns:
            í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = datetime.now()
        results = {
            'success': False,
            'query_phase': {},
            'process_phase': {},
            'statistics': {},
            'errors': []
        }
        
        try:
            logger.info("=== Mail Query â†’ Mail Process í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            logger.info(f"ì‚¬ìš©ì: {user_id}, ì¡°íšŒ ê¸°ê°„: {days_back}ì¼, ìµœëŒ€ ë©”ì¼: {max_mails}ê°œ")
            
            # Phase 1: Mail Query - ë©”ì¼ ì¡°íšŒ
            logger.info("\nğŸ“¥ Phase 1: Mail Query - ë©”ì¼ ë°ì´í„° ì¡°íšŒ")
            query_results = await self._phase1_query_mails(
                user_id, days_back, max_mails, filters
            )
            results['query_phase'] = query_results
            
            if not query_results['success']:
                results['errors'].append("ë©”ì¼ ì¡°íšŒ ì‹¤íŒ¨")
                return results
            
            # Phase 2: Mail Process - ë©”ì¼ ì²˜ë¦¬
            logger.info("\nğŸ”§ Phase 2: Mail Process - ë©”ì¼ ì²˜ë¦¬")
            process_results = await self._phase2_process_mails(
                user_id, 
                query_results['messages']
            )
            results['process_phase'] = process_results
            
            # Phase 3: í†µê³„ ë° ë¶„ì„
            logger.info("\nğŸ“Š Phase 3: í†µê³„ ë¶„ì„")
            statistics = await self._phase3_analyze_results(
                user_id,
                query_results,
                process_results
            )
            results['statistics'] = statistics
            
            # ì „ì²´ ì‹¤í–‰ ì‹œê°„
            total_time = (datetime.now() - start_time).total_seconds()
            results['total_execution_time'] = round(total_time, 2)
            results['success'] = True
            
            logger.info(f"\n=== í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì´ {total_time:.2f}ì´ˆ) ===")
            
        except Exception as e:
            logger.error(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            results['errors'].append(str(e))
            results['total_execution_time'] = (datetime.now() - start_time).total_seconds()
        
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            await self._cleanup()
        
        return results
    
    async def _phase1_query_mails(
        self,
        user_id: str,
        days_back: int,
        max_mails: int,
        additional_filters: Optional[MailQueryFilters]
    ) -> Dict:
        """Phase 1: ë©”ì¼ ì¡°íšŒ"""
        try:
            # ê¸°ë³¸ í•„í„° ì„¤ì •
            date_from = datetime.now() - timedelta(days=days_back)
            
            if additional_filters:
                filters = additional_filters
                if not filters.date_from:
                    filters.date_from = date_from
            else:
                filters = MailQueryFilters(date_from=date_from)
            
            # í˜ì´ì§• ì˜µì…˜
            pagination = PaginationOptions(
                top=min(max_mails, 50),  # í•œ í˜ì´ì§€ë‹¹ ìµœëŒ€ 50ê°œ
                skip=0,
                max_pages=(max_mails // 50) + 1
            )
            
            # í•„ë“œ ì„ íƒ (ì²˜ë¦¬ì— í•„ìš”í•œ í•„ë“œë§Œ)
            select_fields = [
                "id", "subject", "from", "sender", "receivedDateTime",
                "bodyPreview", "body", "hasAttachments", "importance", "isRead"
            ]
            
            # ë©”ì¼ ì¡°íšŒ ìš”ì²­
            request = MailQueryRequest(
                user_id=user_id,
                filters=filters,
                pagination=pagination,
                select_fields=select_fields
            )
            
            # ë©”ì¼ ì¡°íšŒ ì‹¤í–‰
            async with self.mail_query as query:
                response = await query.mail_query_user_emails(request)
            
            # ê²°ê³¼ ì •ë¦¬
            messages = []
            for msg in response.messages[:max_mails]:  # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
                messages.append(msg.model_dump())
            
            return {
                'success': True,
                'total_fetched': response.total_fetched,
                'messages': messages,
                'query_time_ms': response.execution_time_ms,
                'query_info': response.query_info,
                'has_more': response.has_more
            }
            
        except Exception as e:
            logger.error(f"ë©”ì¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'messages': []
            }
    
    async def _phase2_process_mails(
        self,
        user_id: str,
        messages: List[Dict]
    ) -> Dict:
        """Phase 2: ë©”ì¼ ì²˜ë¦¬"""
        start_time = datetime.now()
        
        try:
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            stats = await self.mail_processor.process_mail_batch(
                account_id=user_id,
                mails=messages,
                publish_batch_event=False  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì´ë²¤íŠ¸ ë°œí–‰ ì•ˆí•¨
            )
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # ê°œë³„ ë©”ì¼ ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ ìˆ˜ì§‘ (ìƒìœ„ 3ê°œ)
            sample_results = []
            for mail in messages[:3]:
                result = await self.mail_processor.process_single_mail(user_id, mail)
                sample_results.append({
                    'mail_id': result.mail_id,
                    'subject': result.subject[:50] + '...' if len(result.subject) > 50 else result.subject,
                    'status': result.processing_status.value,
                    'keywords': result.keywords,
                    'error': result.error_message
                })
            
            return {
                'success': True,
                'statistics': stats,
                'processing_time': round(processing_time, 3),
                'average_time_per_mail': round(processing_time / len(messages), 3) if messages else 0,
                'sample_results': sample_results
            }
            
        except Exception as e:
            logger.error(f"ë©”ì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'statistics': {
                    'processed': 0,
                    'skipped': 0,
                    'failed': len(messages),
                    'total': len(messages)
                }
            }
    
    async def _phase3_analyze_results(
        self,
        user_id: str,
        query_results: Dict,
        process_results: Dict
    ) -> Dict:
        """Phase 3: ê²°ê³¼ ë¶„ì„ ë° í†µê³„"""
        try:
            # ê¸°ë³¸ í†µê³„
            stats = {
                'query_stats': {
                    'total_mails_found': query_results.get('total_fetched', 0),
                    'mails_retrieved': len(query_results.get('messages', [])),
                    'query_time_ms': query_results.get('query_time_ms', 0),
                    'has_more_data': query_results.get('has_more', False)
                },
                'process_stats': process_results.get('statistics', {}),
                'performance': {
                    'total_processing_time': process_results.get('processing_time', 0),
                    'avg_time_per_mail': process_results.get('average_time_per_mail', 0),
                    'query_performance': query_results.get('query_info', {}).get('performance_estimate', 'UNKNOWN')
                }
            }
            
            # ì²˜ë¦¬ìœ¨ ê³„ì‚°
            if stats['query_stats']['mails_retrieved'] > 0:
                process_rate = (
                    stats['process_stats'].get('processed', 0) / 
                    stats['query_stats']['mails_retrieved']
                ) * 100
                stats['process_rate'] = round(process_rate, 2)
            else:
                stats['process_rate'] = 0
            
            # í•„í„° íš¨ìœ¨ì„±
            filter_stats = self.mail_processor.get_filter_stats()
            stats['filter_efficiency'] = filter_stats
            
            # í‚¤ì›Œë“œ ë¶„ì„ (ìƒ˜í”Œ ê²°ê³¼ì—ì„œ)
            if process_results.get('sample_results'):
                all_keywords = []
                for result in process_results['sample_results']:
                    all_keywords.extend(result.get('keywords', []))
                
                # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
                from collections import Counter
                keyword_freq = Counter(all_keywords)
                stats['top_keywords'] = keyword_freq.most_common(10)
            
            # DBì—ì„œ ì¶”ê°€ í†µê³„ ì¡°íšŒ
            recent_stats = self._get_recent_processing_stats(user_id)
            if recent_stats:
                stats['recent_history'] = recent_stats
            
            return stats
            
        except Exception as e:
            logger.error(f"í†µê³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {'error': str(e)}
    
    def _get_recent_processing_stats(self, user_id: str) -> Optional[Dict]:
        """ìµœê·¼ ì²˜ë¦¬ í†µê³„ ì¡°íšŒ"""
        try:
            # ìµœê·¼ 24ì‹œê°„ ì²˜ë¦¬ í†µê³„
            query = """
                SELECT 
                    COUNT(*) as total_processed,
                    COUNT(DISTINCT sender) as unique_senders,
                    AVG(json_array_length(keywords)) as avg_keywords_per_mail
                FROM mail_history mh
                JOIN accounts a ON mh.account_id = a.id
                WHERE a.user_id = ? 
                AND mh.processed_at >= datetime('now', '-1 day')
            """
            
            result = self.db_manager.fetch_one(query, (user_id,))
            
            if result:
                return {
                    'last_24h_processed': result['total_processed'] or 0,
                    'unique_senders': result['unique_senders'] or 0,
                    'avg_keywords': round(result['avg_keywords_per_mail'] or 0, 2)
                }
            
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        
        return None
    
    async def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            await self.mail_processor.close()
            await self.mail_query.close()
        except Exception as e:
            logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def print_results(self, results: Dict):
        """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“Š Mail Query â†’ Mail Process í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*70)
        
        if not results.get('success'):
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            for error in results.get('errors', []):
                print(f"  - {error}")
            return
        
        # Query Phase ê²°ê³¼
        print("\nğŸ“¥ Phase 1: Mail Query ê²°ê³¼")
        query = results['query_phase']
        print(f"  - ì´ ë©”ì¼ ìˆ˜: {query['total_fetched']}ê°œ")
        print(f"  - ì¡°íšŒëœ ë©”ì¼: {len(query['messages'])}ê°œ")
        print(f"  - ì¡°íšŒ ì‹œê°„: {query['query_time_ms']}ms")
        print(f"  - ì¶”ê°€ ë°ì´í„°: {'ìˆìŒ' if query['has_more'] else 'ì—†ìŒ'}")
        
        # Process Phase ê²°ê³¼
        print("\nğŸ”§ Phase 2: Mail Process ê²°ê³¼")
        process = results['process_phase']
        stats = process['statistics']
        print(f"  - ì²˜ë¦¬ë¨: {stats['processed']}ê°œ")
        print(f"  - ê±´ë„ˆëœ€: {stats['skipped']}ê°œ")
        print(f"  - ì‹¤íŒ¨: {stats['failed']}ê°œ")
        print(f"  - ì²˜ë¦¬ ì‹œê°„: {process['processing_time']}ì´ˆ")
        print(f"  - í‰ê·  ì‹œê°„: {process['average_time_per_mail']}ì´ˆ/ë©”ì¼")
        
        # ìƒ˜í”Œ ê²°ê³¼
        if process.get('sample_results'):
            print("\nğŸ“‹ ì²˜ë¦¬ ìƒ˜í”Œ:")
            for i, sample in enumerate(process['sample_results'][:3], 1):
                print(f"\n  ë©”ì¼ {i}:")
                print(f"    ì œëª©: {sample['subject']}")
                print(f"    ìƒíƒœ: {sample['status']}")
                if sample['keywords']:
                    print(f"    í‚¤ì›Œë“œ: {', '.join(sample['keywords'])}")
                if sample.get('error'):
                    print(f"    ì˜¤ë¥˜: {sample['error']}")
        
        # í†µê³„ ë¶„ì„
        print("\nğŸ“Š Phase 3: í†µê³„ ë¶„ì„")
        stats = results['statistics']
        print(f"  - ì²˜ë¦¬ìœ¨: {stats['process_rate']}%")
        print(f"  - ì¿¼ë¦¬ ì„±ëŠ¥: {stats['performance']['query_performance']}")
        
        if stats.get('top_keywords'):
            print("\nğŸ·ï¸  ìƒìœ„ í‚¤ì›Œë“œ:")
            for keyword, count in stats['top_keywords'][:5]:
                print(f"    - {keyword}: {count}íšŒ")
        
        if stats.get('recent_history'):
            hist = stats['recent_history']
            print("\nğŸ“ˆ ìµœê·¼ 24ì‹œê°„ í†µê³„:")
            print(f"    - ì²˜ë¦¬ëœ ë©”ì¼: {hist['last_24h_processed']}ê°œ")
            print(f"    - ê³ ìœ  ë°œì‹ ì: {hist['unique_senders']}ëª…")
            print(f"    - í‰ê·  í‚¤ì›Œë“œ: {hist['avg_keywords']}ê°œ/ë©”ì¼")
        
        print(f"\nâ±ï¸  ì „ì²´ ì‹¤í–‰ ì‹œê°„: {results['total_execution_time']}ì´ˆ")
        print("="*70)


async def test_with_filters():
    """í•„í„°ë¥¼ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” í•„í„°ë§ëœ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("-"*50)
    
    tester = MailIntegrationTester()
    
    # íŠ¹ì • ì¡°ê±´ì˜ ë©”ì¼ë§Œ ì²˜ë¦¬
    filters = MailQueryFilters(
        date_from=datetime.now() - timedelta(days=3),  # ìµœê·¼ 3ì¼
        has_attachments=True,                          # ì²¨ë¶€íŒŒì¼ ìˆìŒ
        is_read=False                                  # ì½ì§€ ì•Šì€ ë©”ì¼
    )
    
    results = await tester.test_integration_flow(
        user_id="kimghw",
        days_back=3,
        max_mails=20,
        filters=filters
    )
    
    tester.print_results(results)


async def test_large_batch():
    """ëŒ€ëŸ‰ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“¦ ëŒ€ëŸ‰ ë©”ì¼ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("-"*50)
    
    tester = MailIntegrationTester()
    
    results = await tester.test_integration_flow(
        user_id="kimghw",
        days_back=30,  # 30ì¼ê°„ì˜ ë©”ì¼
        max_mails=100  # ìµœëŒ€ 100ê°œ ì²˜ë¦¬
    )
    
    tester.print_results(results)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Mail Query â†’ Mail Process í†µí•© í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1] == "--filter":
            # í•„í„° í…ŒìŠ¤íŠ¸
            await test_with_filters()
        elif sys.argv[1] == "--large":
            # ëŒ€ëŸ‰ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            await test_large_batch()
        elif sys.argv[1] == "--custom":
            # ì‚¬ìš©ì ì •ì˜ í…ŒìŠ¤íŠ¸
            user_id = sys.argv[2] if len(sys.argv) > 2 else "kimghw"
            days = int(sys.argv[3]) if len(sys.argv) > 3 else 7
            count = int(sys.argv[4]) if len(sys.argv) > 4 else 10
            
            print(f"\nì‚¬ìš©ì ì •ì˜ í…ŒìŠ¤íŠ¸: user={user_id}, days={days}, count={count}")
            
            tester = MailIntegrationTester()
            results = await tester.test_integration_flow(user_id, days, count)
            tester.print_results(results)
        else:
            print("\nì‚¬ìš©ë²•:")
            print("  python test_integration.py              # ê¸°ë³¸ í…ŒìŠ¤íŠ¸")
            print("  python test_integration.py --filter     # í•„í„° í…ŒìŠ¤íŠ¸")
            print("  python test_integration.py --large      # ëŒ€ëŸ‰ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            print("  python test_integration.py --custom [user_id] [days] [count]")
            return
    else:
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
        print("\nğŸ“§ ê¸°ë³¸ í†µí•© í…ŒìŠ¤íŠ¸ (ìµœê·¼ 7ì¼, ìµœëŒ€ 10ê°œ)")
        print("-"*50)
        
        tester = MailIntegrationTester()
        results = await tester.test_integration_flow()
        tester.print_results(results)
        
        # JSONìœ¼ë¡œ ê²°ê³¼ ì €ì¥ ì˜µì…˜
        save_json = input("\nğŸ’¾ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if save_json.lower() == 'y':
            filename = f"integration_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"âœ… ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print("\nğŸ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")


if __name__ == "__main__":
    asyncio.run(main())
