#!/usr/bin/env python3
"""
Mail Processor ê°„ì†Œí™” ë²„ì „ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì™¸ë¶€ì—ì„œ ë©”ì¼ì„ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬í•˜ëŠ” í…ŒìŠ¤íŠ¸
"""
import asyncio
import sys
from datetime import datetime, timedelta
from typing import List, Dict

# ëª¨ë“ˆ ì„í¬íŠ¸
from modules.mail_query import (
    MailQueryOrchestrator,
    MailQueryRequest,
    MailQueryFilters,
    PaginationOptions
)
from modules.mail_process import (
    MailProcessorOrchestrator,
    ProcessingStatus
)
from infra.core.logger import get_logger, update_all_loggers_level
from infra.core.database import get_database_manager
import logging

# Kafka ê´€ë ¨ ë””ë²„ê¹… ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
logging.getLogger("infra.core.kafka_client").setLevel(logging.ERROR)
logging.getLogger("kafka").setLevel(logging.ERROR)
logging.getLogger("aiokafka").setLevel(logging.ERROR)

# ì „ì²´ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
update_all_loggers_level("INFO")
logger = get_logger(__name__)


class MailProcessorTester:
    """Mail Processor ê°„ì†Œí™” ë²„ì „ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.mail_query = MailQueryOrchestrator()
        self.mail_processor = MailProcessorOrchestrator()
        self.db_manager = get_database_manager()
    
    async def test_mail_processing(self, user_id: str = "kimghw", mail_count: int = 5) -> dict:
        """ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜"""
        start_time = datetime.now()
        
        try:
            logger.info("=== Mail Processor í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
            logger.info(f"ëŒ€ìƒ ì‚¬ìš©ì: {user_id}, ì²˜ë¦¬í•  ë©”ì¼ ìˆ˜: {mail_count}")
            
            # 1ë‹¨ê³„: ì™¸ë¶€ì—ì„œ ë©”ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Mail Query ì‚¬ìš©)
            logger.info("\nğŸ“¥ 1ë‹¨ê³„: ì™¸ë¶€ì—ì„œ ë©”ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°")
            mails = await self._fetch_mails_from_external(user_id, mail_count)
            
            if not mails:
                logger.warning("ê°€ì ¸ì˜¨ ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    'success': False,
                    'error': 'ë©”ì¼ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.',
                    'stage': 'fetch'
                }
            
            logger.info(f"âœ… {len(mails)}ê°œ ë©”ì¼ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
            
            # 2ë‹¨ê³„: Mail Processorë¡œ ì²˜ë¦¬
            logger.info("\nğŸ”§ 2ë‹¨ê³„: Mail Processorë¡œ ì²˜ë¦¬")
            
            # ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            if len(mails) == 1:
                result = await self._test_single_mail_processing(user_id, mails[0])
            else:
                # ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
                result = await self._test_batch_mail_processing(user_id, mails)
            
            # 3ë‹¨ê³„: í•„í„° í†µê³„ í™•ì¸
            logger.info("\nğŸ“Š 3ë‹¨ê³„: í•„í„° í†µê³„ í™•ì¸")
            filter_stats = self.mail_processor.get_filter_stats()
            result['filter_stats'] = filter_stats
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = (datetime.now() - start_time).total_seconds()
            result['total_execution_time'] = round(execution_time, 2)
            
            logger.info(f"\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì´ {execution_time:.2f}ì´ˆ) ===")
            
            return result
            
        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'stage': 'test',
                'execution_time': (datetime.now() - start_time).total_seconds()
            }
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            await self._cleanup()
    
    async def _fetch_mails_from_external(self, user_id: str, mail_count: int) -> List[Dict]:
        """ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ë©”ì¼ ê°€ì ¸ì˜¤ê¸° (Mail Query ì‚¬ìš©)"""
        try:
            # ìµœê·¼ 7ì¼ê°„ì˜ ë©”ì¼ ì¡°íšŒ
            date_from = datetime.now() - timedelta(days=7)
            
            request = MailQueryRequest(
                user_id=user_id,
                filters=MailQueryFilters(
                    date_from=date_from
                ),
                pagination=PaginationOptions(
                    top=mail_count,
                    skip=0,
                    max_pages=1
                ),
                select_fields=[
                    "id", "subject", "from", "sender", "receivedDateTime", 
                    "bodyPreview", "body", "hasAttachments", "importance", "isRead"
                ]
            )
            
            async with self.mail_query as query:
                response = await query.mail_query_user_emails(request)
            
            # GraphMailItemì„ Dictë¡œ ë³€í™˜
            mails = []
            for message in response.messages:
                mail_dict = message.model_dump()
                mails.append(mail_dict)
            
            logger.info(f"ì™¸ë¶€ì—ì„œ {len(mails)}ê°œ ë©”ì¼ ê°€ì ¸ì˜´")
            return mails
            
        except Exception as e:
            logger.error(f"ë©”ì¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _test_single_mail_processing(self, user_id: str, mail: Dict) -> dict:
        """ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        logger.info("\nğŸ”¬ ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        logger.info(f"ë©”ì¼ ì œëª©: {mail.get('subject', 'No Subject')[:50]}...")
        
        try:
            # process_single_mail ì§ì ‘ í˜¸ì¶œ
            start_time = datetime.now()
            result = await self.mail_processor.process_single_mail(user_id, mail)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # ê²°ê³¼ ì •ë¦¬
            return {
                'success': True,
                'test_type': 'single',
                'mail_id': result.mail_id,
                'subject': result.subject,
                'sender': result.sender_address,
                'status': result.processing_status.value,
                'keywords': result.keywords,
                'error_message': result.error_message,
                'processing_time': round(processing_time, 3),
                'details': {
                    'sent_time': result.sent_time.isoformat(),
                    'processed_at': result.processed_at.isoformat(),
                    'body_preview': result.body_preview[:100] + '...' if len(result.body_preview) > 100 else result.body_preview
                }
            }
            
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                'success': False,
                'test_type': 'single',
                'error': str(e)
            }
    
    async def _test_batch_mail_processing(self, user_id: str, mails: List[Dict]) -> dict:
        """ë°°ì¹˜ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        logger.info(f"\nğŸ”¬ ë°°ì¹˜ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ({len(mails)}ê°œ)")
        
        try:
            # process_mail_batch í˜¸ì¶œ
            start_time = datetime.now()
            stats = await self.mail_processor.process_mail_batch(
                user_id, 
                mails, 
                publish_batch_event=False  # ë°°ì¹˜ ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰ ì•ˆí•¨
            )
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # ê° ë©”ì¼ì˜ ìƒì„¸ ê²°ê³¼ ìˆ˜ì§‘
            individual_results = []
            
            # ê°œë³„ ë©”ì¼ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ìœ„í•´ ë‹¤ì‹œ ì²˜ë¦¬ (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ ê°€ëŠ¥)
            for mail in mails[:3]:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ í‘œì‹œ
                result = await self.mail_processor.process_single_mail(user_id, mail)
                individual_results.append({
                    'mail_id': result.mail_id,
                    'subject': result.subject[:50] + '...' if len(result.subject) > 50 else result.subject,
                    'status': result.processing_status.value,
                    'keywords': result.keywords
                })
            
            return {
                'success': True,
                'test_type': 'batch',
                'statistics': stats,
                'processing_time': round(processing_time, 3),
                'average_time_per_mail': round(processing_time / len(mails), 3),
                'sample_results': individual_results
            }
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ë©”ì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                'success': False,
                'test_type': 'batch',
                'error': str(e)
            }
    
    async def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            await self.mail_processor.close()
            await self.mail_query.close()
        except Exception as e:
            logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def print_results(self, results: dict):
        """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š Mail Processor í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*60)
        
        if not results.get('success'):
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {results.get('error', 'Unknown error')}")
            print(f"ì‹¤íŒ¨ ë‹¨ê³„: {results.get('stage', 'unknown')}")
            return
        
        test_type = results.get('test_type', 'unknown')
        
        if test_type == 'single':
            print("\nâœ… ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            print(f"ğŸ“§ ë©”ì¼ ID: {results['mail_id']}")
            print(f"ğŸ“‹ ì œëª©: {results['subject']}")
            print(f"ğŸ‘¤ ë°œì‹ ì: {results['sender']}")
            print(f"ğŸ“Š ìƒíƒœ: {results['status']}")
            
            if results['keywords']:
                print(f"ğŸ·ï¸  í‚¤ì›Œë“œ: {', '.join(results['keywords'])}")
            else:
                print("ğŸ·ï¸  í‚¤ì›Œë“œ: ì—†ìŒ")
            
            if results.get('error_message'):
                print(f"âš ï¸  ì˜¤ë¥˜: {results['error_message']}")
            
            print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {results['processing_time']}ì´ˆ")
            
        elif test_type == 'batch':
            print("\nâœ… ë°°ì¹˜ ë©”ì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            stats = results['statistics']
            print(f"ğŸ“Š ì „ì²´ í†µê³„:")
            print(f"  - ì´ ë©”ì¼: {stats['total']}ê°œ")
            print(f"  - ì²˜ë¦¬ë¨: {stats['processed']}ê°œ")
            print(f"  - ê±´ë„ˆëœ€: {stats['skipped']}ê°œ")
            print(f"  - ì‹¤íŒ¨: {stats['failed']}ê°œ")
            print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {results['processing_time']}ì´ˆ")
            print(f"â±ï¸  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {results['average_time_per_mail']}ì´ˆ/ë©”ì¼")
            
            if results.get('sample_results'):
                print("\nğŸ“‹ ìƒ˜í”Œ ê²°ê³¼:")
                for i, sample in enumerate(results['sample_results'], 1):
                    print(f"\n  ë©”ì¼ {i}:")
                    print(f"    ì œëª©: {sample['subject']}")
                    print(f"    ìƒíƒœ: {sample['status']}")
                    if sample['keywords']:
                        print(f"    í‚¤ì›Œë“œ: {', '.join(sample['keywords'])}")
        
        # í•„í„° í†µê³„
        if results.get('filter_stats'):
            stats = results['filter_stats']
            print("\nğŸ” í•„í„° í†µê³„:")
            print(f"  - í•„í„°ë§ í™œì„±í™”: {stats['filtering_enabled']}")
            print(f"  - ì°¨ë‹¨ ë„ë©”ì¸: {stats['blocked_domains_count']}ê°œ")
            print(f"  - ì°¨ë‹¨ í‚¤ì›Œë“œ: {stats['blocked_keywords_count']}ê°œ")
            print(f"  - ì°¨ë‹¨ íŒ¨í„´: {stats['blocked_patterns_count']}ê°œ")
        
        print(f"\nâ±ï¸  ì „ì²´ ì‹¤í–‰ ì‹œê°„: {results.get('total_execution_time', 0)}ì´ˆ")
        print("="*60)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Mail Processor ê°„ì†Œí™” ë²„ì „ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    # ì„¤ì •
    user_id = "kimghw"  # í…ŒìŠ¤íŠ¸í•  ì‚¬ìš©ì ID
    mail_count = 5      # ì²˜ë¦¬í•  ë©”ì¼ ê°œìˆ˜
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1] == "--single":
            mail_count = 1
            print("ğŸ“§ ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ ëª¨ë“œ")
        elif sys.argv[1] == "--batch":
            if len(sys.argv) > 2:
                mail_count = int(sys.argv[2])
            print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ ({mail_count}ê°œ)")
        elif sys.argv[1] == "--clear-data":
            print("ğŸ—‘ï¸  ë°ì´í„° ì´ˆê¸°í™” ëª¨ë“œ")
            db_manager = get_database_manager()
            
            # í…Œì´ë¸” ë°ì´í„° ì´ˆê¸°í™”
            result1 = db_manager.clear_table_data("mail_history")
            print(f"ğŸ“§ mail_history: {result1['message']}")
            
            result2 = db_manager.clear_table_data("processing_logs")
            print(f"ğŸ“ processing_logs: {result2['message']}")
            
            print("\nâœ… ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
            return
    
    # í…ŒìŠ¤í„° ì‹¤í–‰
    tester = MailProcessorTester()
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = await tester.test_mail_processing(user_id, mail_count)
        
        # ê²°ê³¼ ì¶œë ¥
        tester.print_results(results)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("\nğŸ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")


if __name__ == "__main__":
    asyncio.run(main())
