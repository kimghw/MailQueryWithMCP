"""ì²˜ë¦¬ ì„œë¹„ìŠ¤ - ë©”ì¼ ì •ì œ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ì „í•œ íŒŒì¼"""

from typing import Dict, List, Optional

from infra.core.config import get_config
from infra.core.logger import get_logger
from modules.keyword_extractor.keyword_extractor_orchestrator import (
    KeywordExtractorOrchestrator,
)
from modules.keyword_extractor.keyword_extractor_schema import (
    BatchExtractionRequest,
    KeywordExtractionRequest,
)

from ..utilities import MailParser, TextCleaner

logger = get_logger(__name__)


class ProcessingService:
    """ë©”ì¼ ì²˜ë¦¬ ì„œë¹„ìŠ¤ (ë°°ì¹˜ í‚¤ì›Œë“œ ì¶”ì¶œ)"""

    def __init__(self):
        self.text_cleaner = TextCleaner()
        self.mail_parser = MailParser()
        self.keyword_extractor = KeywordExtractorOrchestrator()
        self.config = get_config()
        self.logger = get_logger(__name__)

        # ì„¤ì •ê°’ ë¡œë“œ
        self.min_content_length = int(
            self.config.get_setting("MIN_MAIL_CONTENT_LENGTH", "10")
        )

        # ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€
        self.batch_keyword_extraction = (
            self.config.get_setting("ENABLE_BATCH_KEYWORD_EXTRACTION", "true").lower()
            == "true"
        )

        self.logger.info(
            f"ì²˜ë¦¬ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”: batch_keyword_extraction={self.batch_keyword_extraction}"
        )

    async def process_mails(self, mails: List[Dict]) -> List[Dict]:
        """ë©”ì¼ ì •ì œ ë° í‚¤ì›Œë“œ ì¶”ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)"""
        if not mails:
            return []

        process_stats = {
            "total": len(mails),
            "processed": 0,
            "too_short": 0,
            "keyword_extracted": 0,
            "processing_errors": 0,
        }

        self.logger.info(f"ë©”ì¼ ì²˜ë¦¬ ì‹œì‘: {len(mails)}ê°œ")

        # ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™”ëœ ê²½ìš°
        if self.batch_keyword_extraction:
            processed_mails = await self._process_mails_batch(mails, process_stats)
        else:
            # ê¸°ì¡´ ê°œë³„ ì²˜ë¦¬ ë°©ì‹
            processed_mails = await self._process_mails_individual(mails, process_stats)

        self._log_process_summary(process_stats)
        return processed_mails

    async def _process_mails_batch(self, mails: List[Dict], stats: Dict) -> List[Dict]:
        """ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ë©”ì¼ ì²˜ë¦¬ (ëŒ€ì‹œë³´ë“œ ì´ë²¤íŠ¸ í¬í•¨)"""
        # 1ë‹¨ê³„: ëª¨ë“  ë©”ì¼ ì •ì œ ë° ì¤€ë¹„
        prepared_mails = []

        for i, mail in enumerate(mails):
            try:
                prepared_mail = self._prepare_mail_for_processing(mail)
                if prepared_mail:
                    prepared_mails.append(prepared_mail)
                else:
                    stats["too_short"] += 1
            except Exception as e:
                stats["processing_errors"] += 1
                self.logger.error(f"ë©”ì¼ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue

        # 2ë‹¨ê³„: ë°°ì¹˜ í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        mail_data_for_keywords = []
        for prepared_mail in prepared_mails:
            mail_data_for_keywords.append(
                {
                    "mail_id": prepared_mail.get("id", "unknown"),  # ë©”ì¼ ID ì¶”ê°€
                    "content": prepared_mail["_processed"]["clean_content"],
                    "subject": prepared_mail["_processed"]["refined_mail"].get(
                        "subject", ""
                    ),
                    "sent_time": prepared_mail["_processed"]["sent_time"],
                    "sender_address": prepared_mail["_processed"]["sender_address"],
                    "sender_name": prepared_mail["_processed"]["sender_name"],
                }
            )

        # 3ë‹¨ê³„: í‚¤ì›Œë“œ ë°°ì¹˜ ì¶”ì¶œ (ëŒ€ì‹œë³´ë“œ ì´ë²¤íŠ¸ ìë™ ë°œí–‰)
        if mail_data_for_keywords:
            async with self.keyword_extractor as extractor:
                try:
                    # BatchExtractionRequest ìƒì„±
                    batch_request = BatchExtractionRequest(
                        items=mail_data_for_keywords,
                        batch_size=50,  # ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŒ
                        concurrent_requests=5,
                    )

                    # ë°°ì¹˜ ì¶”ì¶œ ì‹¤í–‰ (ëŒ€ì‹œë³´ë“œ ì´ë²¤íŠ¸ í¬í•¨)
                    batch_response = await extractor.extract_keywords_batch(
                        batch_request
                    )

                    # 4ë‹¨ê³„: ê²°ê³¼ ë³‘í•©
                    for i, prepared_mail in enumerate(prepared_mails):
                        if i < len(batch_response.results):
                            keywords = batch_response.results[i]
                            prepared_mail["_processed"]["keywords"] = keywords
                            if keywords:
                                stats["keyword_extracted"] += 1
                        else:
                            prepared_mail["_processed"]["keywords"] = []

                        stats["processed"] += 1

                except Exception as e:
                    self.logger.error(f"ë°°ì¹˜ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                    # ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë©”ì¼ì— ë¹ˆ í‚¤ì›Œë“œ í• ë‹¹
                    for prepared_mail in prepared_mails:
                        prepared_mail["_processed"]["keywords"] = []
                        stats["processed"] += 1

        return prepared_mails

    async def _process_mails_individual(
        self, mails: List[Dict], stats: Dict
    ) -> List[Dict]:
        """ê°œë³„ ë°©ì‹ìœ¼ë¡œ ë©”ì¼ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)"""
        processed_mails = []

        async with self.keyword_extractor as extractor:
            for mail in mails:
                try:
                    processed_mail = await self._process_single_mail(mail)
                    if processed_mail:
                        processed_mails.append(processed_mail)
                        stats["processed"] += 1

                        if processed_mail.get("_processed", {}).get("keywords"):
                            stats["keyword_extracted"] += 1
                    else:
                        stats["too_short"] += 1

                except Exception as e:
                    stats["processing_errors"] += 1
                    self.logger.error(f"ë©”ì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                    continue

        return processed_mails

    def _prepare_mail_for_processing(self, mail: Dict) -> Optional[Dict]:
        """ë©”ì¼ ì²˜ë¦¬ ì¤€ë¹„ (í‚¤ì›Œë“œ ì¶”ì¶œ ì œì™¸)"""
        # ë©”ì¼ ì •ë³´ ì¶”ì¶œ
        mail_id = self.mail_parser.extract_mail_id(mail)
        sent_time = self.mail_parser.extract_sent_time(mail)

        # ë°œì‹ ì ì •ë³´ ì¶”ì¶œ ì¶”ê°€
        sender_address = self.mail_parser.extract_sender_address(mail)
        sender_name = self.mail_parser.extract_sender_name(mail)

        # í…ìŠ¤íŠ¸ ì •ì œ
        refined_mail = self.text_cleaner.prepare_mail_content(mail)

        # ë‚´ìš© ì¶”ì¶œ ë° ê²°í•©
        subject = refined_mail.get("subject", "")
        body_content = refined_mail.get("body", {}).get("content", "")
        clean_content = f"{subject} {body_content}".strip()

        # ë‚´ìš© ê²€ì¦
        if self.text_cleaner.is_content_too_short(
            clean_content, min_length=self.min_content_length
        ):
            self.logger.debug(f"ë‚´ìš© ë¶€ì¡±: {mail_id}")
            return None

        # ì²˜ë¦¬ëœ ë©”ì¼ ë°ì´í„° êµ¬ì„±
        mail["_processed"] = {
            "mail_id": mail_id,
            "sent_time": sent_time,
            "sender_address": sender_address,
            "sender_name": sender_name,
            "clean_content": clean_content,
            "refined_mail": refined_mail,
            "keywords": [],  # ë‚˜ì¤‘ì— ì±„ì›Œì§ˆ ì˜ˆì •
        }

        # ìµœìƒìœ„ ë ˆë²¨ì—ë„ ì €ì¥ (í˜¸í™˜ì„±ì„ ìœ„í•´)
        mail["sender_address"] = sender_address
        mail["sender_name"] = sender_name

        return mail

    async def _process_single_mail(self, mail: Dict) -> Optional[Dict]:
        """ê°œë³„ ë©”ì¼ ì²˜ë¦¬ (ëŒ€ì‹œë³´ë“œ ì´ë²¤íŠ¸ í¬í•¨)"""
        # ë©”ì¼ ì¤€ë¹„
        prepared_mail = self._prepare_mail_for_processing(mail)
        if not prepared_mail:
            return None

        # ğŸ¯ í‚¤ì›Œë“œ ì¶”ì¶œ ì „ì— ë©”ì¼ ID ì„¤ì •
        mail_id = prepared_mail.get("id", "unknown")
        self.keyword_extractor.extraction_service.set_current_mail_id(mail_id)

        # í‚¤ì›Œë“œ ì¶”ì¶œ ìš”ì²­ ìƒì„±
        extraction_request = KeywordExtractionRequest(
            text=prepared_mail["_processed"]["clean_content"],
            subject=prepared_mail["_processed"]["refined_mail"].get("subject", ""),
            sent_time=prepared_mail["_processed"]["sent_time"],
            sender_address=prepared_mail["_processed"]["sender_address"],
            sender_name=prepared_mail["_processed"]["sender_name"],
            max_keywords=int(self.config.get_setting("MAX_KEYWORDS_PER_MAIL", "5")),
            use_structured_response=self.config.get_setting(
                "ENABLE_STRUCTURED_EXTRACTION", "true"
            ).lower()
            == "true",
        )

        # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰ (ëŒ€ì‹œë³´ë“œ ì´ë²¤íŠ¸ ìë™ ë°œí–‰)
        response = await self.keyword_extractor.extract_keywords(extraction_request)
        prepared_mail["_processed"]["keywords"] = response.keywords

        return prepared_mail

    def _log_process_summary(self, stats: Dict):
        """ì²˜ë¦¬ ìš”ì•½ ë¡œê¹…"""
        self.logger.info(
            f"ì²˜ë¦¬ ì™„ë£Œ: {stats['processed']}/{stats['total']} "
            f"(ë‚´ìš©ë¶€ì¡±={stats['too_short']}, "
            f"í‚¤ì›Œë“œì¶”ì¶œ={stats['keyword_extracted']}, "
            f"ì˜¤ë¥˜={stats['processing_errors']})"
        )

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            await self.keyword_extractor.close()
        except Exception as e:
            self.logger.warning(f"í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
