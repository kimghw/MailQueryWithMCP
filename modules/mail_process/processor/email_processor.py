"""ë©”ì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""

import logging
import shutil
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

from infra.utils.datetime_utils import utc_now
from .process_options import ProcessOptions, TempFileCleanupPolicy
from .result import EmailProcessResult, AttachmentResult, BatchProcessResult
from .handlers.email_saver import EmailSaver
from .handlers.attachment_handler import AttachmentHandler
from .handlers.text_converter import TextConverter
from ..utils import sanitize_filename

logger = logging.getLogger(__name__)


class EmailProcessor:
    """ë©”ì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, options: ProcessOptions):
        """
        Args:
            options: ì²˜ë¦¬ ì˜µì…˜
        """
        options.validate()
        self.options = options

        # í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        self.email_saver = EmailSaver(options.output_dir) if options.save_email else None
        self.attachment_handler = AttachmentHandler(options.output_dir) if options.save_attachments else None
        self.text_converter = TextConverter() if options.convert_to_text else None

        # ì„ì‹œ íŒŒì¼ ì¶”ì  (í˜„ì¬ ì„¸ì…˜ì˜ ì„ì‹œ íŒŒì¼ë“¤)
        self.temp_files: List[Path] = []
        self.temp_dirs: List[Path] = []

    async def process_email(
        self,
        graph_client,
        email_data: Dict[str, Any]
    ) -> EmailProcessResult:
        """
        ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬

        Args:
            graph_client: Microsoft Graph client
            email_data: ë©”ì¼ ë°ì´í„°

        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        # DELETE_ON_NEW_QUERY ì •ì±…: ìƒˆ ì¿¼ë¦¬ ì‹œì‘ ì‹œ ì´ì „ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if self.options.temp_cleanup_policy == TempFileCleanupPolicy.DELETE_ON_NEW_QUERY:
            self._cleanup_previous_temp_files()

        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        email_id = self._get_field(email_data, 'id', 'unknown')
        subject = self._get_field(email_data, 'subject', 'No Subject')
        sender_info = self._extract_sender_info(email_data)
        received_time = self._get_field(email_data, 'received_date_time', utc_now())

        # ê²°ê³¼ ê°ì²´ ì´ˆê¸°í™”
        result = EmailProcessResult(
            email_id=email_id,
            subject=subject,
            sender=sender_info['email'],
            received_datetime=received_time.isoformat() if isinstance(received_time, datetime) else str(received_time)
        )

        try:
            # ë©”ì¼ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
            email_dir = self._create_email_directory(
                email_data,
                sender_info,
                received_time
            )
            result.email_dir = email_dir

            # 1. ë©”ì¼ ë³¸ë¬¸ ì €ì¥
            if self.options.save_email:
                await self._save_email_content(email_data, email_dir, result)

            # 2. ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
            if self.options.save_attachments and self._get_field(email_data, 'has_attachments', False):
                await self._process_attachments(
                    graph_client,
                    email_data,
                    email_dir,
                    result
                )

            logger.info(f"âœ… Successfully processed email: {subject[:50]}")

            # DELETE_ON_RETURN ì •ì±…: í•¨ìˆ˜ ë°˜í™˜ ì§ì „ì— ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if self.options.temp_cleanup_policy == TempFileCleanupPolicy.DELETE_ON_RETURN:
                self.cleanup_temp_files(result)

        except Exception as e:
            error_msg = f"Error processing email {email_id}: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

        return result

    async def process_emails_batch(
        self,
        graph_client,
        emails: List[Dict[str, Any]]
    ) -> BatchProcessResult:
        """
        ì—¬ëŸ¬ ë©”ì¼ ì¼ê´„ ì²˜ë¦¬

        Args:
            graph_client: Microsoft Graph client
            emails: ë©”ì¼ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¼ê´„ ì²˜ë¦¬ ê²°ê³¼
        """
        total = len(emails)
        results = []
        successful = 0
        failed = 0

        logger.info(f"ğŸ“§ Processing {total} emails...")

        for idx, email_data in enumerate(emails, 1):
            logger.info(f"Processing {idx}/{total}: {self._get_field(email_data, 'subject', 'No Subject')[:50]}")

            result = await self.process_email(graph_client, email_data)
            results.append(result)

            if result.has_errors():
                failed += 1
            else:
                successful += 1

        batch_result = BatchProcessResult(
            total_emails=total,
            successful=successful,
            failed=failed,
            results=results
        )

        # DELETE_ON_RETURN ì •ì±…: ë°°ì¹˜ ì™„ë£Œ ì‹œ ëª¨ë“  ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if self.options.temp_cleanup_policy == TempFileCleanupPolicy.DELETE_ON_RETURN:
            self.cleanup_batch_temp_files(batch_result)

        logger.info(f"âœ… Batch processing complete: {successful}/{total} successful")
        return batch_result

    def _create_email_directory(
        self,
        email_data: Dict[str, Any],
        sender_info: Dict[str, str],
        received_time
    ) -> Path:
        """ë©”ì¼ë³„ ë””ë ‰í† ë¦¬ ìƒì„± (ì„ì‹œ ì €ì¥ì†Œ ì˜µì…˜ ì§€ì›)"""
        # ì„ì‹œ ì €ì¥ì†Œ ì‚¬ìš© ì‹œ
        if self.options.should_use_temp_storage():
            base_dir = self.options.temp_dir
        else:
            base_dir = self.options.output_dir

        user_dir = base_dir / self.options.user_id

        if not self.options.create_subfolder_per_email:
            user_dir.mkdir(parents=True, exist_ok=True)
            # ì„ì‹œ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ì¶”ì 
            if self.options.should_use_temp_storage():
                self._register_temp_dir(user_dir)
            return user_dir

        # í´ë”ëª… ìƒì„±
        if not isinstance(received_time, datetime):
            received_time = utc_now()

        folder_name = self.options.subfolder_format.format(
            subject=sanitize_filename(self._get_field(email_data, 'subject', 'NoSubject')[:50]),
            date=received_time.strftime('%Y%m%d_%H%M%S'),
            sender=sanitize_filename(sender_info['email'])
        )

        email_dir = user_dir / folder_name
        email_dir.mkdir(parents=True, exist_ok=True)

        # ì„ì‹œ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ì¶”ì 
        if self.options.should_use_temp_storage():
            self._register_temp_dir(email_dir)

        return email_dir

    async def _save_email_content(
        self,
        email_data: Dict[str, Any],
        email_dir: Path,
        result: EmailProcessResult
    ):
        """ë©”ì¼ ë³¸ë¬¸ ì €ì¥"""
        try:
            save_result = await self.email_saver.save_email(
                email_data,
                email_dir,
                include_headers=self.options.include_email_headers,
                save_html=self.options.save_html_version
            )

            result.email_saved = True
            result.email_text_path = save_result['text_path']
            result.email_html_path = save_result['html_path']

        except Exception as e:
            error_msg = f"Failed to save email content: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    async def _process_attachments(
        self,
        graph_client,
        email_data: Dict[str, Any],
        email_dir: Path,
        result: EmailProcessResult
    ):
        """ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ (ìœ ì—°í•œ ê²½ë¡œ ì˜µì…˜ ì§€ì›)"""
        attachments = self._get_field(email_data, 'attachments', [])
        if not attachments:
            return

        try:
            # ì²¨ë¶€íŒŒì¼ ì €ì¥ ê²½ë¡œ ê²°ì •
            attachment_dir = self.options.get_attachment_base_dir(email_dir)
            attachment_dir.mkdir(parents=True, exist_ok=True)

            # ì„ì‹œ ì €ì¥ì†Œ ì‚¬ìš© ì‹œ ë””ë ‰í† ë¦¬ ì¶”ì 
            if self.options.should_use_temp_storage():
                self._register_temp_dir(attachment_dir)

            # ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
            saved_files = await self.attachment_handler.download_and_save_attachments(
                graph_client,
                self._get_field(email_data, 'id'),
                attachments,
                attachment_dir
            )

            # í…ìŠ¤íŠ¸ ë³€í™˜ (ì˜µì…˜)
            for saved_file in saved_files:
                att_result = AttachmentResult(
                    original_name=saved_file['name'],
                    saved_path=saved_file['path'],
                    size=saved_file['size']
                )

                if saved_file['error']:
                    result.errors.append(f"Attachment error: {saved_file['error']}")

                # ì €ì¥ëœ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì¶”ì 
                if self.options.should_use_temp_storage() and saved_file['path']:
                    self._register_temp_file(saved_file['path'])

                # í…ìŠ¤íŠ¸ ë³€í™˜
                if self.options.convert_to_text and saved_file['path']:
                    self._convert_attachment_to_text(saved_file['path'], att_result)

                result.attachments.append(att_result)

        except Exception as e:
            error_msg = f"Failed to process attachments: {str(e)}"
            logger.error(error_msg)
            result.errors.append(error_msg)

    def _convert_attachment_to_text(
        self,
        file_path: Path,
        att_result: AttachmentResult
    ):
        """ì²¨ë¶€íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            convert_result = self.text_converter.convert_file_to_text(
                file_path,
                save_text=self.options.save_converted_text,
                delete_original=self.options.delete_original_after_convert
            )

            if convert_result['success']:
                att_result.converted = True
                att_result.converted_text_path = convert_result['text_path']

                if self.options.return_text_content:
                    att_result.converted_text_content = convert_result['text_content']

                logger.info(f"âœ… Converted {file_path.name} to text")
            else:
                att_result.conversion_error = convert_result['error']
                logger.warning(f"âš ï¸ Failed to convert {file_path.name}: {convert_result['error']}")

        except Exception as e:
            error_msg = f"Error converting {file_path.name}: {str(e)}"
            logger.error(error_msg)
            att_result.conversion_error = error_msg

    def _extract_sender_info(self, email_data: Dict[str, Any]) -> Dict[str, str]:
        """ë°œì‹ ì ì •ë³´ ì¶”ì¶œ"""
        sender_info = {
            'name': 'Unknown',
            'email': 'unknown@email.com'
        }

        if hasattr(email_data, 'from_address'):
            if email_data.from_address and isinstance(email_data.from_address, dict):
                email_addr = email_data.from_address.get('emailAddress', {})
                sender_info['email'] = email_addr.get('address', '')
                sender_info['name'] = email_addr.get('name', '')
            return sender_info

        if 'from_address' in email_data:
            from_addr = email_data['from_address']
            if isinstance(from_addr, dict):
                email_addr = from_addr.get('emailAddress', {})
                sender_info['email'] = email_addr.get('address', '')
                sender_info['name'] = email_addr.get('name', '')
        elif 'sender' in email_data:
            sender = email_data['sender']
            if isinstance(sender, dict):
                email_addr = sender.get('emailAddress', {})
                sender_info['email'] = email_addr.get('address', '')
                sender_info['name'] = email_addr.get('name', '')

        return sender_info

    def _get_field(self, email_data: Dict[str, Any], field_name: str, default: Any = None) -> Any:
        """í•„ë“œ ê°’ ì¶”ì¶œ"""
        if hasattr(email_data, field_name):
            return getattr(email_data, field_name, default)

        if isinstance(email_data, dict):
            if field_name in email_data:
                return email_data.get(field_name, default)

            camel_case = ''.join(word.capitalize() if i > 0 else word for i, word in enumerate(field_name.split('_')))
            if camel_case in email_data:
                return email_data.get(camel_case, default)

        return default

    # ===== ì„ì‹œ íŒŒì¼ ê´€ë¦¬ ë©”ì„œë“œ =====

    def _register_temp_file(self, file_path: Path):
        """ì„ì‹œ íŒŒì¼ ë“±ë¡"""
        if file_path and file_path not in self.temp_files:
            self.temp_files.append(file_path)
            logger.debug(f"Registered temp file: {file_path}")

    def _register_temp_dir(self, dir_path: Path):
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ë“±ë¡"""
        if dir_path and dir_path not in self.temp_dirs:
            self.temp_dirs.append(dir_path)
            logger.debug(f"Registered temp dir: {dir_path}")

    def cleanup_temp_files(self, result: EmailProcessResult):
        """
        ë‹¨ì¼ ë©”ì¼ ì²˜ë¦¬ ê²°ê³¼ì˜ ì„ì‹œ íŒŒì¼ ì‚­ì œ

        Args:
            result: ë©”ì¼ ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.options.should_use_temp_storage():
            return

        deleted_count = 0

        # ê²°ê³¼ì— í¬í•¨ëœ íŒŒì¼ ì‚­ì œ
        if result.email_dir and result.email_dir.exists():
            try:
                shutil.rmtree(result.email_dir)
                deleted_count += 1
                logger.info(f"ğŸ—‘ï¸ Deleted temp directory: {result.email_dir}")
            except Exception as e:
                logger.error(f"Failed to delete temp directory {result.email_dir}: {e}")

        logger.info(f"ğŸ—‘ï¸ Cleanup complete: {deleted_count} items deleted")

    def cleanup_batch_temp_files(self, batch_result: BatchProcessResult):
        """
        ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ì˜ ëª¨ë“  ì„ì‹œ íŒŒì¼ ì‚­ì œ

        Args:
            batch_result: ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.options.should_use_temp_storage():
            return

        deleted_count = 0

        # ê° ê²°ê³¼ì˜ ë””ë ‰í† ë¦¬ ì‚­ì œ
        for result in batch_result.results:
            if result.email_dir and result.email_dir.exists():
                try:
                    shutil.rmtree(result.email_dir)
                    deleted_count += 1
                except Exception as e:
                    logger.error(f"Failed to delete temp directory {result.email_dir}: {e}")

        logger.info(f"ğŸ—‘ï¸ Batch cleanup complete: {deleted_count} items deleted")

    def _cleanup_previous_temp_files(self):
        """
        ì´ì „ ì¿¼ë¦¬ì˜ ì„ì‹œ íŒŒì¼ ì‚­ì œ (DELETE_ON_NEW_QUERY ì •ì±…)
        """
        if not self.options.should_use_temp_storage():
            return

        deleted_files = 0
        deleted_dirs = 0

        # ì´ì „ì— ë“±ë¡ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        for temp_file in self.temp_files:
            if temp_file.exists():
                try:
                    temp_file.unlink()
                    deleted_files += 1
                except Exception as e:
                    logger.error(f"Failed to delete temp file {temp_file}: {e}")

        # ì´ì „ì— ë“±ë¡ëœ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
        for temp_dir in self.temp_dirs:
            if temp_dir.exists():
                try:
                    shutil.rmtree(temp_dir)
                    deleted_dirs += 1
                except Exception as e:
                    logger.error(f"Failed to delete temp directory {temp_dir}: {e}")

        # ì¶”ì  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        self.temp_files.clear()
        self.temp_dirs.clear()

        if deleted_files > 0 or deleted_dirs > 0:
            logger.info(f"ğŸ—‘ï¸ Cleaned up previous session: {deleted_files} files, {deleted_dirs} dirs")
