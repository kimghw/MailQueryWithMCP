#!/usr/bin/env python3
"""
ë©”ì¼ í ì €ì¥ í…ŒìŠ¤íŠ¸ - ë” ë§ì€ ë©”ì¼ ì¡°íšŒ
"""

import asyncio
from datetime import datetime, timedelta
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.mail_process.mail_processor_orchestrator import MailProcessorOrchestrator
from modules.mail_query.mail_query_orchestrator import MailQueryOrchestrator
from modules.mail_query.mail_query_schema import (
    MailQueryFilters,
    PaginationOptions,
    MailQueryRequest,
)
from infra.core.logger import get_logger
from infra.core.database import get_database_manager

logger = get_logger(__name__)


async def test_with_more_mails(user_id: str):
    """ë” ë§ì€ ë©”ì¼ì„ ì¡°íšŒí•˜ëŠ” í…ŒìŠ¤íŠ¸"""

    print(f"\nğŸ§ª í™•ì¥ëœ ë©”ì¼ í ì €ì¥ í…ŒìŠ¤íŠ¸: {user_id}")
    print("=" * 80)

    orchestrator = MailProcessorOrchestrator()
    db = get_database_manager()

    try:
        # ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ì„œ ì‹œì‘
        await orchestrator.start_background_processor()

        # ê¸°ì¡´ ë©”ì¼ íˆìŠ¤í† ë¦¬ í™•ì¸
        existing_count = db.fetch_one(
            """
            SELECT COUNT(*) as count 
            FROM mail_history mh
            JOIN accounts a ON mh.account_id = a.id
            WHERE a.user_id = ?
            """,
            (user_id,),
        )

        print(
            f"\nğŸ“Š ê¸°ì¡´ ì €ì¥ëœ ë©”ì¼: {existing_count['count'] if existing_count else 0}ê°œ"
        )

        # ë” ê¸´ ê¸°ê°„ê³¼ ë” ë§ì€ í˜ì´ì§€ë¡œ ì„¤ì •
        filters = MailQueryFilters(
            date_from=datetime.now() - timedelta(days=90)  # 90ì¼ë¡œ í™•ì¥
        )

        # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì • - ë” ë§ì€ ë©”ì¼ ì¡°íšŒ
        pagination = PaginationOptions(
            top=100, max_pages=10  # í˜ì´ì§€ë‹¹ 100ê°œë¡œ ì¦ê°€  # ìµœëŒ€ 10í˜ì´ì§€ (1000ê°œ)
        )

        print(f"\nğŸ“§ ë©”ì¼ ì¡°íšŒ ì„¤ì •:")
        print(f"  - ì¡°íšŒ ê¸°ê°„: ìµœê·¼ 90ì¼")
        print(f"  - í˜ì´ì§€ë‹¹ ë©”ì¼ ìˆ˜: 100ê°œ")
        print(f"  - ìµœëŒ€ í˜ì´ì§€: 10ê°œ")
        print(f"  - ìµœëŒ€ ì¡°íšŒ ê°€ëŠ¥: 1000ê°œ")

        # ë©”ì¼ ì¡°íšŒ ë° í ì €ì¥
        print(f"\nâ³ ë©”ì¼ ì¡°íšŒ ì¤‘...")
        start_time = datetime.now()

        # ë©”ì¼ ì¡°íšŒ
        mail_query_orchestrator = MailQueryOrchestrator()
        try:
            query_request = MailQueryRequest(
                user_id=user_id, filters=filters, pagination=pagination
            )

            query_response = await mail_query_orchestrator.mail_query_user_emails(
                query_request
            )

            print(f"ğŸ“§ ë©”ì¼ ì¡°íšŒ ì™„ë£Œ: {query_response.total_fetched}ê°œ")

            # íì— ì €ì¥
            if query_response.messages:
                # account_id ì¡°íšŒ (user_idë¡œë¶€í„°)
                account_record = db.fetch_one(
                    "SELECT id FROM accounts WHERE user_id = ?", (user_id,)
                )
                if not account_record:
                    raise ValueError(f"ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}")

                account_id = account_record["id"]

                result = await orchestrator.enqueue_mail_batch(
                    account_id=account_id, mails=query_response.messages
                )
            else:
                result = {
                    "account_id": user_id,
                    "total": 0,
                    "enqueued": 0,
                    "filtered": 0,
                    "duplicates": 0,
                    "errors": 0,
                    "queue_size": 0,
                    "success": True,
                }

        finally:
            await mail_query_orchestrator.close()

        elapsed_time = (datetime.now() - start_time).total_seconds()

        print(f"\nâœ… í ì €ì¥ ì™„ë£Œ!")
        print(f"  - íì— ì €ì¥ëœ ë©”ì¼: {result.get('enqueued', 0)}ê°œ")
        print(f"  - ì¤‘ë³µ ë©”ì¼: {result.get('duplicates', 0)}ê°œ")
        print(f"  - í˜„ì¬ í í¬ê¸°: {result.get('queue_size', 0)}ê°œ")
        print(f"  - ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ")

        # í ë°°ì¹˜ í¬ê¸° í™•ì¸
        queue_status = await orchestrator.queue_service.get_queue_status()
        print(f"\nğŸ“¦ í ì„¤ì •:")
        print(f"  - ë°°ì¹˜ í¬ê¸°: {queue_status['batch_size']}ê°œ")
        print(f"  - í ë¹„ì–´ìˆìŒ: {queue_status['is_empty']}")

        # í ì²˜ë¦¬ ì§„í–‰ ëª¨ë‹ˆí„°ë§
        if not queue_status["is_empty"]:
            print(f"\nâ³ í ì²˜ë¦¬ ì§„í–‰ ëª¨ë‹ˆí„°ë§ (30ì´ˆ)...")

            for i in range(6):  # 5ì´ˆë§ˆë‹¤ 6ë²ˆ = 30ì´ˆ
                await asyncio.sleep(5)

                current_status = await orchestrator.get_processing_stats()
                queue_size = current_status["queue"]["queue_size"]

                print(f"  [{(i+1)*5}ì´ˆ] ë‚¨ì€ í: {queue_size}ê°œ")

                if queue_size == 0:
                    print("  âœ… í ì²˜ë¦¬ ì™„ë£Œ!")
                    break

        # ìµœì¢… í†µê³„
        final_stats = await orchestrator.get_processing_stats()
        print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
        print(f"  - DB ì €ì¥ëœ ì „ì²´ ë©”ì¼: {final_stats['database']['total_mails']}ê°œ")
        print(f"  - ì˜¤ëŠ˜ ì²˜ë¦¬ëœ ë©”ì¼: {final_stats['database']['today_mails']}ê°œ")
        print(f"  - ì´ë²ˆ ì£¼ ì²˜ë¦¬ëœ ë©”ì¼: {final_stats['database']['week_mails']}ê°œ")

    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    finally:
        await orchestrator.cleanup()
        print("\nâœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


async def check_mail_history_duplicates(user_id: str):
    """ë©”ì¼ íˆìŠ¤í† ë¦¬ ì¤‘ë³µ ì²´í¬"""

    print(f"\nğŸ” ë©”ì¼ íˆìŠ¤í† ë¦¬ ì¤‘ë³µ ë¶„ì„: {user_id}")
    print("=" * 80)

    db = get_database_manager()

    # ì „ì²´ ë©”ì¼ ìˆ˜
    total_query = """
        SELECT COUNT(*) as total_count
        FROM mail_history mh
        JOIN accounts a ON mh.account_id = a.id
        WHERE a.user_id = ?
    """

    # ê³ ìœ  ë©”ì‹œì§€ ID ìˆ˜
    unique_query = """
        SELECT COUNT(DISTINCT message_id) as unique_count
        FROM mail_history mh
        JOIN accounts a ON mh.account_id = a.id
        WHERE a.user_id = ?
    """

    # ìµœê·¼ ë©”ì¼ ì •ë³´
    recent_query = """
        SELECT 
            message_id,
            subject,
            received_time,
            processed_at
        FROM mail_history mh
        JOIN accounts a ON mh.account_id = a.id
        WHERE a.user_id = ?
        ORDER BY processed_at DESC
        LIMIT 10
    """

    total_result = db.fetch_one(total_query, (user_id,))
    unique_result = db.fetch_one(unique_query, (user_id,))
    recent_mails = db.fetch_all(recent_query, (user_id,))

    total_count = total_result["total_count"] if total_result else 0
    unique_count = unique_result["unique_count"] if unique_result else 0

    print(f"ğŸ“Š ë©”ì¼ íˆìŠ¤í† ë¦¬ í†µê³„:")
    print(f"  - ì „ì²´ ë ˆì½”ë“œ: {total_count}ê°œ")
    print(f"  - ê³ ìœ  ë©”ì‹œì§€: {unique_count}ê°œ")
    print(f"  - ì¤‘ë³µ ë ˆì½”ë“œ: {total_count - unique_count}ê°œ")

    if recent_mails:
        print(f"\nğŸ“§ ìµœê·¼ ì²˜ë¦¬ëœ ë©”ì¼ (10ê°œ):")
        for mail in recent_mails:
            print(f"  - {mail['subject'][:50]}...")
            print(f"    ìˆ˜ì‹ : {mail['received_time']}")
            print(f"    ì²˜ë¦¬: {mail['processed_at']}")
            print()


async def check_queue_status_and_process():
    """í ìƒíƒœ í™•ì¸ ë° ì²˜ë¦¬"""

    print(f"\nğŸ“Š í ìƒíƒœ í™•ì¸ ë° ì²˜ë¦¬")
    print("=" * 80)

    orchestrator = MailProcessorOrchestrator()

    try:
        # í˜„ì¬ í ìƒíƒœ í™•ì¸
        initial_status = await orchestrator.get_processing_stats()
        queue_size = initial_status["queue"]["queue_size"]

        print(f"\ní˜„ì¬ í ìƒíƒœ:")
        print(f"  - í í¬ê¸°: {queue_size}ê°œ")
        print(f"  - ë°°ì¹˜ í¬ê¸°: {initial_status['queue']['batch_size']}ê°œ")
        print(f"  - í ë¹„ì–´ìˆìŒ: {initial_status['queue']['is_empty']}")

        if queue_size == 0:
            print("\nâœ… íê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬í•  ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

            # DB í†µê³„ í‘œì‹œ
            print(f"\nğŸ“Š DB í†µê³„:")
            print(
                f"  - ì „ì²´ ì €ì¥ëœ ë©”ì¼: {initial_status['database']['total_mails']}ê°œ"
            )
            print(
                f"  - ì˜¤ëŠ˜ ì²˜ë¦¬ëœ ë©”ì¼: {initial_status['database']['today_mails']}ê°œ"
            )
            return

        # íì— ë©”ì¼ì´ ìˆìœ¼ë©´ ì²˜ë¦¬ ì‹œì‘
        process_choice = input(
            f"\n{queue_size}ê°œì˜ ë©”ì¼ì´ íì— ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): "
        )

        if process_choice.lower() == "y":
            # ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ì„œ ì‹œì‘
            await orchestrator.start_background_processor()
            print("\nâ³ í ì²˜ë¦¬ ì¤‘...")

            # ì²˜ë¦¬ ì§„í–‰ ëª¨ë‹ˆí„°ë§
            processed_count = 0
            for i in range(60):  # ìµœëŒ€ 5ë¶„ (5ì´ˆ * 60 = 300ì´ˆ)
                await asyncio.sleep(5)

                current_status = await orchestrator.get_processing_stats()
                current_queue_size = current_status["queue"]["queue_size"]

                # ì²˜ë¦¬ëœ ë©”ì¼ ìˆ˜ ê³„ì‚°
                newly_processed = queue_size - current_queue_size - processed_count
                processed_count += newly_processed

                print(
                    f"  [{(i+1)*5}ì´ˆ] ë‚¨ì€ í: {current_queue_size}ê°œ (ì²˜ë¦¬ë¨: {processed_count}ê°œ)"
                )

                if current_queue_size == 0:
                    print(f"\nâœ… í ì²˜ë¦¬ ì™„ë£Œ! ì´ {processed_count}ê°œ ë©”ì¼ ì²˜ë¦¬ë¨")
                    break

                # ì²˜ë¦¬ê°€ ë©ˆì¶˜ ê²ƒ ê°™ìœ¼ë©´ í™•ì¸
                if i > 0 and newly_processed == 0:
                    if not current_status["background_processor"]["running"]:
                        print("\nâš ï¸  ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ì„œê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        break

            # ìµœì¢… í†µê³„
            final_status = await orchestrator.get_processing_stats()
            print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
            print(f"  - ë‚¨ì€ í: {final_status['queue']['queue_size']}ê°œ")
            print(f"  - DB ì „ì²´ ë©”ì¼: {final_status['database']['total_mails']}ê°œ")
            print(f"  - ì˜¤ëŠ˜ ì²˜ë¦¬ëœ ë©”ì¼: {final_status['database']['today_mails']}ê°œ")

        else:
            print("\ní ì²˜ë¦¬ë¥¼ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")

            # í ì´ˆê¸°í™” ì˜µì…˜
            clear_choice = input("\níë¥¼ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if clear_choice.lower() == "y":
                cleared = await orchestrator.queue_service.clear_queue()
                print(f"âœ… íê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. {cleared}ê°œ ì•„ì´í…œ ì œê±°ë¨")

    finally:
        await orchestrator.cleanup()
        print("\nâœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


async def clear_mail_history_option():
    """ë©”ì¼ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì˜µì…˜"""

    confirm = input("\nâš ï¸  ë©”ì¼ íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if confirm.lower() == "y":
        db = get_database_manager()
        db.execute_query("DELETE FROM mail_history")
        print("âœ… ë©”ì¼ íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
    return False


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\nğŸš€ í™•ì¥ëœ ë©”ì¼ í í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨")
    print("=" * 80)

    user_id = input("í…ŒìŠ¤íŠ¸í•  ê³„ì • IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: krsdtp): ").strip()

    if not user_id:
        print("âŒ ê³„ì • IDê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    print("\ní…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (ìµœê·¼ 30ì¼, 100ê°œ)")
    print("2. í™•ì¥ í…ŒìŠ¤íŠ¸ (ìµœê·¼ 90ì¼, 1000ê°œ)")
    print("3. ë©”ì¼ íˆìŠ¤í† ë¦¬ ë¶„ì„")
    print("4. ë©”ì¼ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” í›„ í…ŒìŠ¤íŠ¸")

    choice = input("\nì„ íƒ (1-4): ").strip()

    if choice == "1":
        # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ê°„ë‹¨íˆ í…ŒìŠ¤íŠ¸
        orchestrator = MailProcessorOrchestrator()
        db = get_database_manager()

        try:
            await orchestrator.start_background_processor()

            # ë©”ì¼ ì¡°íšŒ
            mail_query_orchestrator = MailQueryOrchestrator()
            try:
                query_request = MailQueryRequest(
                    user_id=user_id,
                    filters=MailQueryFilters(
                        date_from=datetime.now() - timedelta(days=30)
                    ),
                    pagination=PaginationOptions(top=50, max_pages=2),
                )

                query_response = await mail_query_orchestrator.mail_query_user_emails(
                    query_request
                )

                # íì— ì €ì¥
                if query_response.messages:
                    # account_id ì¡°íšŒ
                    account_record = db.fetch_one(
                        "SELECT id FROM accounts WHERE user_id = ?", (user_id,)
                    )
                    if not account_record:
                        raise ValueError(f"ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}")

                    account_id = account_record["id"]

                    result = await orchestrator.enqueue_mail_batch(
                        account_id=account_id, mails=query_response.messages
                    )
                else:
                    result = {"enqueued": 0, "duplicates": 0}

            finally:
                await mail_query_orchestrator.close()

            print(f"\nâœ… ê²°ê³¼:")
            print(f"  - íì— ì €ì¥: {result.get('enqueued', 0)}ê°œ")
            print(f"  - ì¤‘ë³µ: {result.get('duplicates', 0)}ê°œ")

        finally:
            await orchestrator.cleanup()

    elif choice == "2":
        await test_with_more_mails(user_id)

    elif choice == "3":
        await check_mail_history_duplicates(user_id)

    elif choice == "4":
        if await clear_mail_history_option():
            await test_with_more_mails(user_id)

    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
