#!/usr/bin/env python3
"""
ëª¨ë“  ê³„ì •ì˜ ë©”ì¼ ì¡°íšŒ ë° ì²˜ë¦¬ í†µí•© í…ŒìŠ¤í„° (ìˆ˜ì •ë³¸)
"""

import sys
import os

# Python ê²½ë¡œì— í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any
import json
from collections import defaultdict

# ì§ì ‘ import
from modules.mail_query.mail_query_orchestrator import MailQueryOrchestrator
from modules.mail_query.mail_query_schema import MailQueryRequest, MailQueryFilters, PaginationOptions
from modules.mail_process.mail_processor_orchestrator import MailProcessorOrchestrator

from infra.core.database import get_database_manager
from infra.core.logger import get_logger, update_all_loggers_level
from infra.core.config import get_config

# ë¡œê·¸ ë ˆë²¨ ì„¤ì •
update_all_loggers_level("INFO")
logger = get_logger(__name__)


class AllAccountsFullProcessTester:
    """ëª¨ë“  ê³„ì •ì˜ ë©”ì¼ ì¡°íšŒ ë° ì²˜ë¦¬ í†µí•© í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.mail_query = MailQueryOrchestrator()
        self.mail_processor = MailProcessorOrchestrator()
        self.db = get_database_manager()
        self.config = get_config()
        
    async def get_all_active_accounts(self) -> List[Dict[str, Any]]:
        """í™œì„±í™”ëœ ëª¨ë“  ê³„ì • ì¡°íšŒ (í…ŒìŠ¤íŠ¸ ê³„ì • ì œì™¸)"""
        query = """
            SELECT 
                user_id, 
                user_name, 
                email,
                is_active,
                status,
                last_sync_time
            FROM accounts 
            WHERE is_active = 1
            AND user_id NOT IN ('test_user', 'test', 'nonexistent', 'temp_user', 'demo_user')  -- í…ŒìŠ¤íŠ¸ ê³„ì • ì œì™¸
            AND user_id NOT LIKE 'test_%'  -- test_ë¡œ ì‹œì‘í•˜ëŠ” ê³„ì • ì œì™¸
            AND user_id NOT LIKE 'temp_%'  -- temp_ë¡œ ì‹œì‘í•˜ëŠ” ê³„ì • ì œì™¸
            ORDER BY user_id
        """
        
        accounts = self.db.fetch_all(query)
        return [dict(account) for account in accounts]
    
    async def process_account(
        self, 
        user_id: str,
        user_name: str,
        days_back: int = 60,
        max_mails: int = 10
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ê³„ì •ì˜ ë©”ì¼ ì¡°íšŒ ë° ì²˜ë¦¬"""
        
        start_time = datetime.now()
        result = {
            "user_id": user_id,
            "user_name": user_name,
            "query_success": False,
            "process_success": False,
            "total_mails_found": 0,
            "mails_processed": 0,
            "processing_stats": {
                "success": 0,
                "skipped": 0,
                "failed": 0,
                "filtered": 0,
                "duplicate": 0
            },
            "keywords_extracted": [],
            "execution_time": {
                "query_ms": 0,
                "process_ms": 0,
                "total_ms": 0
            },
            "errors": []
        }
        
        try:
            # 1. Mail Query - ë©”ì¼ ì¡°íšŒ
            logger.info(f"\nğŸ“¥ [{user_id}] ë©”ì¼ ì¡°íšŒ ì‹œì‘...")
            query_start = datetime.now()
            
            request = MailQueryRequest(
                user_id=user_id,
                filters=MailQueryFilters(
                    date_from=datetime.now() - timedelta(days=days_back)
                ),
                pagination=PaginationOptions(
                    top=max_mails,
                    skip=0,
                    max_pages=1
                ),
                select_fields=[
                    "id", "subject", "from", "sender", 
                    "receivedDateTime", "bodyPreview", "body",
                    "hasAttachments", "importance", "isRead"
                ]
            )
            
            async with self.mail_query as orchestrator:
                query_response = await orchestrator.mail_query_user_emails(request)
            
            result["query_success"] = True
            result["total_mails_found"] = query_response.total_fetched
            result["execution_time"]["query_ms"] = query_response.execution_time_ms
            
            logger.info(f"âœ… [{user_id}] ë©”ì¼ ì¡°íšŒ ì™„ë£Œ: {query_response.total_fetched}ê°œ")
            
            if query_response.total_fetched == 0:
                logger.info(f"âš ï¸ [{user_id}] ì¡°íšŒëœ ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                result["execution_time"]["total_ms"] = int(
                    (datetime.now() - start_time).total_seconds() * 1000
                )
                return result
            
            # 2. Mail Process - ë©”ì¼ ì²˜ë¦¬
            logger.info(f"ğŸ”§ [{user_id}] ë©”ì¼ ì²˜ë¦¬ ì‹œì‘...")
            process_start = datetime.now()
            
            # ì˜¬ë°”ë¥¸ ë©”ì„œë“œ í˜¸ì¶œ: process_mails
            process_stats = await self.mail_processor.process_mails(
                account_id=user_id,
                mails=[mail.model_dump() for mail in query_response.messages],
                publish_batch_event=False  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì´ë²¤íŠ¸ ë°œí–‰ ì•ˆí•¨
            )
            
            result["process_success"] = True
            
            # í†µê³„ ë§¤í•‘ ìˆ˜ì •
            result["mails_processed"] = process_stats.get("total_mails", 0)
            result["processing_stats"] = {
                "success": process_stats.get("saved_mails", 0),  # ì‹¤ì œ ì €ì¥ëœ ë©”ì¼
                "skipped": process_stats.get("skipped_mails", 0),  # í•„í„°ë§ëœ ë©”ì¼
                "failed": process_stats.get("db_errors", 0),  # DB ì˜¤ë¥˜
                "filtered": process_stats.get("filtered_out", 0),  # í•„í„°ë§ëœ ë©”ì¼
                "duplicate": process_stats.get("duplicate_mails", 0),  # ì¤‘ë³µ ë©”ì¼
                "processed": process_stats.get("processed_mails", 0),  # ì²˜ë¦¬ëœ ë©”ì¼
                "events": process_stats.get("events_published", 0)  # ë°œí–‰ëœ ì´ë²¤íŠ¸
            }
            
            # í•„í„° ì´ìœ  ìƒì„¸
            if "filter_reasons" in process_stats:
                result["filter_details"] = {
                    "total": process_stats.get("skipped_mails", 0),
                    "reasons": process_stats["filter_reasons"]
                }
            
            # í‚¤ì›Œë“œ ìˆ˜ì§‘
            if "keywords" in process_stats:
                result["keywords_extracted"] = process_stats["keywords"]
            
            result["execution_time"]["process_ms"] = int(
                (datetime.now() - process_start).total_seconds() * 1000
            )
            
            logger.info(
                f"âœ… [{user_id}] ë©”ì¼ ì²˜ë¦¬ ì™„ë£Œ: "
                f"ì €ì¥={process_stats.get('saved_mails', 0)}, "
                f"ì¤‘ë³µ={process_stats.get('duplicate_mails', 0)}, "
                f"í•„í„°ë§={process_stats.get('skipped_mails', 0)}, "
                f"ì´ë²¤íŠ¸={process_stats.get('events_published', 0)}"
            )
            
        except Exception as e:
            error_msg = f"ê³„ì • ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            logger.error(f"âŒ [{user_id}] {error_msg}", exc_info=True)
            result["errors"].append(error_msg)
        
        finally:
            result["execution_time"]["total_ms"] = int(
                (datetime.now() - start_time).total_seconds() * 1000
            )
        
        return result
    
    async def test_all_accounts(
        self,
        days_back: int = 60,
        max_mails_per_account: int = 20,
        save_results: bool = True
    ):
        """ëª¨ë“  ê³„ì • í†µí•© í…ŒìŠ¤íŠ¸"""
        
        print("\n" + "ğŸš€ " * 20)
        print("ëª¨ë“  ê³„ì • ë©”ì¼ ì¡°íšŒ ë° ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸")
        print("ğŸš€ " * 20)
        print(f"\nğŸ“… ì„¤ì •:")
        print(f"  - ì¡°íšŒ ê¸°ê°„: ìµœê·¼ {days_back}ì¼")
        print(f"  - ê³„ì •ë‹¹ ìµœëŒ€ ë©”ì¼: {max_mails_per_account}ê°œ")
        print(f"  - ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("\n" + "=" * 80)
        
        # 1. í™œì„± ê³„ì • ì¡°íšŒ
        accounts = await self.get_all_active_accounts()
        print(f"\nğŸ“‹ í™œì„± ê³„ì •: {len(accounts)}ê°œ (í…ŒìŠ¤íŠ¸ ê³„ì • ì œì™¸)")
        for i, account in enumerate(accounts, 1):
            print(f"  {i}. {account['user_id']} ({account['user_name']})")
        
        # 2. ê° ê³„ì • ì²˜ë¦¬
        print("\n" + "=" * 80)
        print("ğŸ“§ ê³„ì •ë³„ ì²˜ë¦¬ ì‹œì‘")
        print("=" * 80)
        
        all_results = []
        total_stats = {
            "accounts": len(accounts),
            "successful_accounts": 0,
            "total_mails_found": 0,
            "total_mails_processed": 0,
            "total_saved": 0,
            "total_duplicate": 0,
            "total_filtered": 0,
            "total_events": 0,
            "all_keywords": []
        }
        
        for i, account in enumerate(accounts, 1):
            print(f"\n[{i}/{len(accounts)}] ì²˜ë¦¬ ì¤‘: {account['user_id']}")
            print("-" * 60)
            
            result = await self.process_account(
                user_id=account['user_id'],
                user_name=account['user_name'],
                days_back=days_back,
                max_mails=max_mails_per_account
            )
            
            all_results.append(result)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if result["query_success"] and result["process_success"]:
                total_stats["successful_accounts"] += 1
            
            total_stats["total_mails_found"] += result["total_mails_found"]
            total_stats["total_mails_processed"] += result["mails_processed"]
            total_stats["total_saved"] += result["processing_stats"]["success"]
            total_stats["total_duplicate"] += result["processing_stats"]["duplicate"]
            total_stats["total_filtered"] += result["processing_stats"]["skipped"]
            total_stats["total_events"] += result["processing_stats"].get("events", 0)
            total_stats["all_keywords"].extend(result["keywords_extracted"])
            
            # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
            print(f"  ğŸ“Š ê²°ê³¼:")
            print(f"     - ì¡°íšŒëœ ë©”ì¼: {result['total_mails_found']}ê°œ")
            print(f"     - ì²˜ë¦¬ ê²°ê³¼: ì €ì¥={result['processing_stats']['success']}, "
                  f"ì¤‘ë³µ={result['processing_stats']['duplicate']}, "
                  f"í•„í„°ë§={result['processing_stats']['skipped']}")
            print(f"     - ì´ë²¤íŠ¸ ë°œí–‰: {result['processing_stats'].get('events', 0)}ê°œ")
            
            # í•„í„°ë§ ìƒì„¸
            if result.get('filter_details') and result['filter_details'].get('reasons'):
                print(f"     - í•„í„°ë§ ìƒì„¸:")
                for reason, count in result['filter_details']['reasons'].items():
                    print(f"       â€¢ {reason}: {count}ê°œ")
            
            print(f"     - ì‹¤í–‰ ì‹œê°„: ì¡°íšŒ={result['execution_time']['query_ms']}ms, "
                  f"ì²˜ë¦¬={result['execution_time']['process_ms']}ms")
        
        # 3. ì „ì²´ í†µê³„
        print("\n" + "=" * 80)
        print("ğŸ“Š ì „ì²´ í†µê³„")
        print("=" * 80)
        
        print(f"\nâœ… ê³„ì • ì²˜ë¦¬ ê²°ê³¼:")
        print(f"  - ì „ì²´ ê³„ì •: {total_stats['accounts']}ê°œ")
        print(f"  - ì„±ê³µ ê³„ì •: {total_stats['successful_accounts']}ê°œ")
        print(f"  - ì‹¤íŒ¨ ê³„ì •: {total_stats['accounts'] - total_stats['successful_accounts']}ê°œ")
        
        print(f"\nğŸ“§ ë©”ì¼ ì²˜ë¦¬ í†µê³„:")
        print(f"  - ì¡°íšŒëœ ì´ ë©”ì¼: {total_stats['total_mails_found']}ê°œ")
        print(f"  - ì²˜ë¦¬ ì‹œë„: {total_stats['total_mails_processed']}ê°œ")
        print(f"  - ì €ì¥ëœ ë©”ì¼: {total_stats['total_saved']}ê°œ")
        print(f"  - ì¤‘ë³µ ë©”ì¼: {total_stats['total_duplicate']}ê°œ")
        print(f"  - í•„í„°ë§ëœ ë©”ì¼: {total_stats['total_filtered']}ê°œ")
        print(f"  - ë°œí–‰ëœ ì´ë²¤íŠ¸: {total_stats['total_events']}ê°œ")
        
        # ì„±ê³µë¥  ê³„ì‚°
        if total_stats['total_mails_processed'] > 0:
            save_rate = (total_stats['total_saved'] / total_stats['total_mails_processed']) * 100
            print(f"  - ì €ì¥ë¥ : {save_rate:.1f}%")
        
        # í‚¤ì›Œë“œ ë¶„ì„
        unique_keywords = list(set(total_stats["all_keywords"]))
        print(f"\nğŸ”‘ í‚¤ì›Œë“œ ë¶„ì„:")
        print(f"  - ì´ í‚¤ì›Œë“œ ìˆ˜: {len(total_stats['all_keywords'])}ê°œ")
        print(f"  - ê³ ìœ  í‚¤ì›Œë“œ ìˆ˜: {len(unique_keywords)}ê°œ")
        
        # ì‹¤í–‰ ì‹œê°„ ë¶„ì„
        total_query_time = sum(r['execution_time']['query_ms'] for r in all_results)
        total_process_time = sum(r['execution_time']['process_ms'] for r in all_results)
        total_time = sum(r['execution_time']['total_ms'] for r in all_results)
        
        print(f"\nâ±ï¸  ì‹¤í–‰ ì‹œê°„ ë¶„ì„:")
        print(f"  - ì´ ì¡°íšŒ ì‹œê°„: {total_query_time:,}ms ({total_query_time/1000:.1f}ì´ˆ)")
        print(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {total_process_time:,}ms ({total_process_time/1000:.1f}ì´ˆ)")
        print(f"  - ì´ ì‹¤í–‰ ì‹œê°„: {total_time:,}ms ({total_time/1000:.1f}ì´ˆ)")
        print(f"  - í‰ê·  ì‹œê°„/ê³„ì •: {total_time/len(accounts):.0f}ms")
        
        # 4. ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
        print(f"\nğŸ“‹ ê³„ì •ë³„ ìƒì„¸ ê²°ê³¼:")
        print(f"{'ê³„ì •':<15} {'ì¡°íšŒ':<8} {'ì €ì¥':<8} {'ì¤‘ë³µ':<8} {'í•„í„°ë§':<8} {'ì´ë²¤íŠ¸':<8} {'ì‹œê°„(ì´ˆ)':<10}")
        print("-" * 85)
        
        for result in all_results:
            print(f"{result['user_id']:<15} "
                  f"{result['total_mails_found']:<8} "
                  f"{result['processing_stats']['success']:<8} "
                  f"{result['processing_stats']['duplicate']:<8} "
                  f"{result['processing_stats']['skipped']:<8} "
                  f"{result['processing_stats'].get('events', 0):<8} "
                  f"{result['execution_time']['total_ms']/1000:<10.1f}")
        
        # 5. ê²°ê³¼ ì €ì¥
        if save_results:
            filename = f"mail_process_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            save_data = {
                "test_info": {
                    "test_date": datetime.now().isoformat(),
                    "days_back": days_back,
                    "max_mails_per_account": max_mails_per_account
                },
                "summary": total_stats,
                "detailed_results": all_results
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {filename}")
        
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        return {
            "summary": total_stats,
            "results": all_results
        }
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.mail_query.close()
        await self.mail_processor.close()


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    days_back = 60
    max_mails = 20
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help":
            print("ì‚¬ìš©ë²•: python mail_query_process.py [days] [max_mails]")
            print("  days: ì¡°íšŒí•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸: 60)")
            print("  max_mails: ê³„ì •ë‹¹ ìµœëŒ€ ë©”ì¼ ìˆ˜ (ê¸°ë³¸: 20)")
            return
        
        days_back = int(sys.argv[1]) if len(sys.argv) > 1 else 60
        max_mails = int(sys.argv[2]) if len(sys.argv) > 2 else 20
    
    tester = AllAccountsFullProcessTester()
    
    try:
        await tester.test_all_accounts(
            days_back=days_back,
            max_mails_per_account=max_mails,
            save_results=True
        )
        
    finally:
        await tester.close()


if __name__ == "__main__":
    asyncio.run(main())
